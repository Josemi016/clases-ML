{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f4006a",
   "metadata": {},
   "source": [
    "# Misión \"Catálogo Exoplanetario\" – Práctica K-Means y clasificación con Árboles y SVM\n",
    "\n",
    "Bienvenido/a a la **Patrulla de Análisis de Exoplanetas (PAE)**. Formas parte de un equipo de científicos de datos\n",
    "asignado a la **Estación Orbital Kepler**, donde se reciben continuamente mediciones procedentes de sondas y\n",
    "telescopios repartidos por toda la galaxia.\n",
    "\n",
    "Hace unas horas ha llegado un nuevo lote de información desde una patrulla espacial automática. Los astrónomos han\n",
    "confirmado que se trata de cientos de **exoplanetas**, pero aún no existe una clasificación clara de sus tipos:\n",
    "gigantes gaseosos, mundos rocosos, super-Tierras, etc. Tu equipo ha sido encargado de **descubrir patrones** en esos\n",
    "datos y proponer una taxonomía inicial de exoplanetas que después pueda utilizar el resto de la flota.\n",
    "\n",
    "Para ello, trabajarás con un catálogo de exoplanetas confirmados y tu misión será:\n",
    "\n",
    "1. **Descubrir tipos de exoplanetas (no supervisado)**  \n",
    "   - Seleccionar un conjunto de **variables físicas** (masa, radio, periodo orbital, etc.).  \n",
    "   - Aplicar **K-Means** para agrupar los exoplanetas en varios clusters y analizar qué tipo de mundos aparecen.\n",
    "\n",
    "2. **Crear una columna de clasificación a partir de K-Means**  \n",
    "   - Convertir los clusters obtenidos en una **columna de clase** (por ejemplo `tipo_planeta`).  \n",
    "   - Asignar nombres descriptivos a cada tipo (p. ej. “Gigantes calientes/fríos”, “Super-Tierras”, etc.).\n",
    "\n",
    "3. **Entrenar modelos supervisados para imitar esa clasificación**  \n",
    "   - Entrenar un **árbol de decisión** y comparar la **accuracy** en train vs test según la profundidad.  \n",
    "   - Entrenar tres modelos **SVM** con kernels distintos (`linear`, `poly`, `rbf`) y comparar sus matrices de confusión.\n",
    "\n",
    "4. **Documentar la misión en un informe**  \n",
    "   - Redactar un **informe en Word** explicando las decisiones tomadas, los resultados obtenidos y la interpretación\n",
    "     científica de los tipos de exoplanetas encontrados.\n",
    "\n",
    "> Tu objetivo final es proponer al **Comité Científico de la Estación Kepler** una primera clasificación fiable de los\n",
    "> exoplanetas del catálogo, respaldada por análisis de datos y modelos de Machine Learning.\n",
    "\n",
    "\n",
    "Fuente de datos: https://dataherb.github.io/flora/nasa_exoplanet_archive/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308f52b",
   "metadata": {},
   "source": [
    "## 1. Carga de librerías y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013101d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from IPython.display import display\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Librerías cargadas correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3434eec7",
   "metadata": {},
   "source": [
    "## 2. Carga del catálogo de exoplanetas\n",
    "\n",
    "Puedes descargar el CSV y llamarlo `confirmed_exoplanets.csv` o dejar que el notebook lo lea desde GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b145339",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_filename = \"confirmed_exoplanets.csv\"\n",
    "url_backup = \"https://raw.githubusercontent.com/InterImm/nasa-exoplanet-archive/master/dataset/confirmed_exoplanets.csv\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(local_filename)\n",
    "    origen = f\"archivo local: {local_filename}\"\n",
    "except FileNotFoundError:\n",
    "    print(f\"No se ha encontrado `{local_filename}`. Descargando desde la URL...\")\n",
    "    df = pd.read_csv(url_backup)\n",
    "    origen = \"descarga online desde GitHub\"\n",
    "\n",
    "print(\"Datos cargados desde\", origen)\n",
    "print(\"Número de filas y columnas:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628c9bc",
   "metadata": {},
   "source": [
    "## 3. EDA – Reconocimiento del catálogo exoplanetario\n",
    "\n",
    "Antes de lanzar algoritmos como si fuéramos autopilotos de la nave, el **Comité Científico de la Estación Kepler-Σ**\n",
    "exige una fase de *reconocimiento de datos*. Acabas de recibir el catálogo bruto de exoplanetas y, como analista de la\n",
    "Patrulla de Análisis de Exoplanetas, tu primera tarea es entender **qué información traen realmente las sondas**.\n",
    "\n",
    "En esta sección deberás:\n",
    "\n",
    "- Revisar la **lista completa de columnas** disponibles en el catálogo (identificadores, magnitudes físicas, banderas, etc.).\n",
    "- Comprobar los **tipos de datos** (numéricos, cadenas, flags…) para distinguir qué columnas son útiles para análisis cuantitativo.\n",
    "- Analizar la **cantidad de valores nulos** por columna para detectar medidas poco fiables o casi vacías.\n",
    "- Centrarse después en un conjunto de **magnitudes físicas** que el propio Comité ya ha preseleccionado como candidatas\n",
    "  para estudiar tipos de exoplanetas.\n",
    "\n",
    "El dataset tiene más de 70 columnas, pero el equipo científico ha filtrado previamente aquellas que considera más relevantes\n",
    "desde el punto de vista físico para esta misión. Estas serán tus **variables candidatas** para trabajar con K-Means:\n",
    "\n",
    "- `pl_orbper`  – periodo orbital (días)  \n",
    "- `pl_orbsmax` – semieje mayor (UA)  \n",
    "- `pl_orbeccen` – excentricidad  \n",
    "- `pl_orbincl` – inclinación (grados)  \n",
    "- `pl_bmassj` – masa del planeta (M·Júpiter)  \n",
    "- `pl_radj` – radio del planeta (R·Júpiter)  \n",
    "- `pl_dens` – densidad del planeta (g/cm³)  \n",
    "- `st_teff` – temperatura efectiva de la estrella (K)  \n",
    "- `st_mass` – masa estelar (M·Solar)  \n",
    "- `st_rad` – radio estelar (R·Solar)  \n",
    "- `st_dist` / `gaia_dist` – distancia a la estrella (pc)  \n",
    "- `st_optmag` / `gaia_gmag` – magnitud aparente  \n",
    "\n",
    "En el EDA deberás:\n",
    "\n",
    "- Comprobar cuáles de estas columnas **están realmente presentes** en el archivo que has cargado.\n",
    "- Observar sus rangos, unidades y posibles outliers.\n",
    "- Valorar cuántos valores nulos tiene cada una y si son utilizables sin o con poca limpieza.\n",
    "\n",
    "Más adelante, a partir de este conjunto preseleccionado, **elegirás un subconjunto de variables físicas**\n",
    "para aplicar K-Means y construir tu propuesta de tipos de exoplanetas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62207021",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_fisicas_recomendadas = [\n",
    "    \"pl_orbper\", \"pl_orbsmax\", \"...\"\n",
    "]\n",
    "\n",
    "columnas = [c for c in columnas_fisicas_recomendadas if c in df.columns]\n",
    "print(\"Columnas físicas presentes:\")\n",
    "print(columnas)\n",
    "\n",
    "df_phys = df[columnas].copy()\n",
    "display(df_phys.describe())\n",
    "\n",
    "#####\n",
    "## COMPLETAR CON UN EDA MÁS PROFUNDO COMO HEMOS VISTO EN CLASE\n",
    "## - Comprobar valores nulos por columna y comentarlos.\n",
    "## - Hacer al menos: 1 histograma de una variable del planeta, 1 histograma de una variable de la estrella o 1 diagrama de dispersión (scatter) entre dos variables que te parezcan interesantes.\n",
    "## - Comentar brevemente qué rangos de valores observas y si ves posibles outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffde70bd",
   "metadata": {},
   "source": [
    "### 3.2 Dispersión 2D (exploratoria)\n",
    "\n",
    "Con las columnas físicas ya identificadas, el Comité Científico de la Estación Kepler te pide un **primer mapa 2D**\n",
    "de los exoplanetas. La idea es simular la pantalla del **radar científico** de la patrulla: en cada eje colocarás\n",
    "una magnitud física y observarás cómo se distribuyen los mundos.\n",
    "\n",
    "En esta parte debes:\n",
    "\n",
    "- Elegir **dos columnas** de `df_phys` (por ejemplo, periodo orbital vs masa, radio vs masa, etc.).\n",
    "- Representar un **diagrama de dispersión (scatterplot)** para visualizar los exoplanetas.\n",
    "- Utilizar **escala logarítmica** en ambos ejes (cuando tenga sentido físico) para ver mejor las nubes de puntos.\n",
    "- Probar **al menos 3 combinaciones distintas** de pares de variables y anotar qué ves:\n",
    "  - ¿Hay zonas con mucha concentración de puntos?\n",
    "  - ¿Se intuyen grupos o “familias” de exoplanetas?\n",
    "  - ¿Existen valores extremos (outliers) que podrían dar lugar a tipos muy raros?\n",
    "\n",
    "> Piensa qué pares de variables pueden ayudarte a separar mejor los distintos tipos de exoplanetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_x = \"\"   # cámbialo\n",
    "feature_y = \"\"    # cámbialo\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_phys, x=feature_x, y=feature_y, alpha=0.5, s=25)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(f\"{feature_x} (log)\")\n",
    "plt.ylabel(f\"{feature_y} (log)\")\n",
    "plt.title(\"Dispersión inicial de exoplanetas\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a6d7b",
   "metadata": {},
   "source": [
    "## 4. K-Means: descubrimiento de tipos de exoplanetas\n",
    "\n",
    "### 4.1 Selección de variables para K-Means\n",
    "\n",
    "El Comité Científico de la Estación Kepler ha decidido que, para esta primera misión, el algoritmo de agrupamiento\n",
    "(K-Means) solo trabajará con un **panel reducido de sensores**. No tiene sentido lanzar todos los instrumentos a la vez:\n",
    "cuantas más variables metamos, más difícil será interpretar después qué significa cada grupo.\n",
    "\n",
    "Tu tarea en esta fase es:\n",
    "\n",
    "- Elegir entre **2 y 4 columnas** de las variables físicas que has analizado en el EDA (`df_phys`).\n",
    "- Comprobar rápidamente cómo son esos datos: rangos, posibles valores extremos y número de nulos.\n",
    "- Crear un DataFrame reducido (`df_km`) que contenga **solo las filas** donde esas variables estén disponibles.\n",
    "\n",
    "Piensa que lo que selecciones aquí será la “vista del universo” que tendrá K-Means.  \n",
    "Si eliges mal los sensores, los tipos de exoplanetas que descubras podrían no tener ningún sentido físico.\n",
    "Más adelante tendrás que **justificar en el informe** por qué escogiste esas variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa esta lista con las variables físicas que quieras usar en K-Means (deben estar dentro de `df_phys.columns`)\n",
    "features_kmeans = [c for c in [\"\"] if c in df_phys.columns]\n",
    "\n",
    "print(\"Variables seleccionadas para K-Means:\", features_kmeans)\n",
    "\n",
    "# DataFrame reducido solo con las filas que tienen datos en TODAS esas columnas\n",
    "df_km = df_phys.dropna(subset=features_kmeans).copy()\n",
    "\n",
    "print(\"Tamaño original (df_phys):\", df_phys.shape)\n",
    "print(\"Tamaño tras limpiar NaN para K-Means (df_km):\", df_km.shape)\n",
    "\n",
    "# Resumen rápido de las variables elegidas\n",
    "display(df_km[features_kmeans].describe())\n",
    "\n",
    "#####\n",
    "## TAREA – EDA 2.0 DE LAS VARIABLES ELEGIDAS:\n",
    "## - Mostrar el número de valores nulos por columna en df_km (debería ser 0 en features_kmeans).\n",
    "## - Dibujar al menos un histograma por cada variable seleccionada.\n",
    "## - Comentar si hay rangos muy amplios o valores claramente extremos.\n",
    "## - Añadir una breve conclusión en tu informe: ¿por qué crees que estas variables son buenas para que K-Means descubra tipos de exoplanetas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992b44c",
   "metadata": {},
   "source": [
    "### 4.2 Escalado y método del codo\n",
    "\n",
    "Antes de lanzar el algoritmo K-Means, el ordenador central de la Estación Kepler-Σ te recuerda que los sensores no\n",
    "miden todas las magnitudes en la misma escala: unas están en **días**, otras en **masas de Júpiter**, otras en\n",
    "**radios solares**… Si no haces nada, las variables con números “grandes” dominarán la distancia y K-Means\n",
    "ignorará las demás.\n",
    "\n",
    "En esta fase vas a:\n",
    "\n",
    "1. **Escalar** las variables seleccionadas con `StandardScaler`.\n",
    "2. Probar varios valores de **K** (número de clusters) y calcular la **inercia** de K-Means.\n",
    "3. Representar la inercia en función de K y buscar el famoso **“método del codo”**.\n",
    "\n",
    "> En tu informe deberás **comentar la gráfica**:  \n",
    "> – ¿Dónde ves el codo?  \n",
    "> – ¿Qué valores de K te parecen razonables para describir tipos de exoplanetas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de las variables seleccionadas para K-Means\n",
    "scaler = StandardScaler()\n",
    "X_km = df_km[features_kmeans].values\n",
    "X_km_scaled = scaler.fit_transform(X_km)\n",
    "\n",
    "\n",
    "# Cálculo de la inercia para varios valores de K\n",
    "k_values = range(2, 10)\n",
    "inertias = []\n",
    "\n",
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    km.fit(X_km_scaled)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(list(k_values), inertias, marker=\"o\")\n",
    "plt.xticks(list(k_values))\n",
    "plt.xlabel(\"Número de clusters K\")\n",
    "plt.ylabel(\"Inercia\")\n",
    "plt.title(\"Método del codo\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a0602",
   "metadata": {},
   "source": [
    "### 4.3 Entrenamiento final de K-Means y primera interpretación científica\n",
    "\n",
    "Tras analizar la curva del codo, el Comité Científico de la Estación Kepler te pide que elijas un **valor concreto de K**\n",
    "para esta misión. Ese será el número de “tipos provisionales de exoplanetas” que el ordenador central va a distinguir.\n",
    "\n",
    "En esta fase debes:\n",
    "\n",
    "1. Fijar un valor de `k_elegido` basándote en la gráfica del codo y en tu criterio científico.\n",
    "2. Entrenar el modelo K-Means definitivo con ese K.\n",
    "3. Asignar a cada exoplaneta el número de cluster correspondiente y contar **cuántos planetas hay en cada grupo**.\n",
    "4. Empezar a interpretar los resultados:\n",
    "   - ¿Hay clusters muy poblados y otros casi vacíos?\n",
    "   - ¿Aparece algún cluster con muy pocos planetas (posibles **casos raros / outliers**)?\n",
    "   - ¿Crees que todos los clusters deberían considerarse “tipos oficiales” o alguno es demasiado pequeño?\n",
    "\n",
    "> Estas frecuencias serán clave más adelante, cuando uses estos clusters como etiquetas para entrenar el árbol de decisión y las SVM. \n",
    "> Un cluster con 1 solo planeta puede ser científicamente interesante, pero estadísticamente inestable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_elegido =    #\n",
    "print(\"Usaremos K =\", k_elegido)\n",
    "\n",
    "kmeans_final = KMeans(n_clusters=k_elegido, random_state=42, n_init=10)\n",
    "clusters = kmeans_final.fit_predict(X_km_scaled)\n",
    "\n",
    "# Guardamos el número de cluster en el DataFrame\n",
    "df_km[\"cluster_kmeans\"] = clusters\n",
    "\n",
    "print(\"\\nFrecuencia de cada cluster:\")\n",
    "freq_clusters = df_km[\"cluster_kmeans\"].value_counts().sort_index()\n",
    "print(freq_clusters)\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Copia estas frecuencias en tu informe y comenta:\n",
    "#   * ¿Qué cluster es el más poblado? ¿Y el menos poblado?\n",
    "#   * ¿Hay algún cluster con muy pocos exoplanetas?\n",
    "# - Reflexiona: ¿tratarías esos clusters diminutos como tipos oficiales de planeta o como \"mundos raros/outliers\" que hay que analizar aparte? ¿Por qué?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462375ae",
   "metadata": {},
   "source": [
    "### 4.4 Visualización 2D de los clusters (espacio original)\n",
    "\n",
    "Ya tienes a cada exoplaneta asignado a un cluster de K-Means. El siguiente paso es pedirle al sistema de visualización\n",
    "de la Estación Kepler un **mapa 2D coloreado por tipo**.\n",
    "\n",
    "En esta vista:\n",
    "\n",
    "- Los ejes X e Y serán dos de las variables físicas que has usado en K-Means.\n",
    "- Cada punto es un exoplaneta.\n",
    "- El color indica a qué **cluster** pertenece.\n",
    "\n",
    "Tu objetivo es comprobar visualmente si K-Means ha encontrado grupos con cierta forma lógica (nubes compactas,\n",
    "zonas separadas, etc.) y localizar posibles **mundos extremos** que se queden aislados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fbd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista 2D – espacio original (valores sin escalar)\n",
    "plot_x = features_kmeans[0]\n",
    "plot_y = features_kmeans[1] if len(features_kmeans) > 1 else features_kmeans[0]\n",
    "\n",
    "print(\"Eje X:\", plot_x)\n",
    "print(\"Eje Y:\", plot_y)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_km,\n",
    "    x=plot_x,\n",
    "    y=plot_y,\n",
    "    hue=\"cluster_kmeans\",\n",
    "    palette=\"tab10\",\n",
    "    s=35,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Escalas logarítmicas si tiene sentido físico\n",
    "plt.xscale(\"log\")\n",
    "if plot_y != plot_x:\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(f\"{plot_x} (escala log)\")\n",
    "plt.ylabel(f\"{plot_y} (escala log)\")\n",
    "plt.title(\"Clusters creados por K-Means (2D – espacio original)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "# TAREA a comentar tu informe:\n",
    "# - Cambia plot_x y plot_y para probar otras combinaciones de variables.\n",
    "# - Comenta en tu informe si los clusters se ven bien separados o si se mezclan.\n",
    "# - Señala si hay planetas muy alejados de los demás."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f994ca1",
   "metadata": {},
   "source": [
    "### 4.5 Visualización 3D de los clusters (espacio original)\n",
    "\n",
    "El radar científico de la estación también permite una **vista tridimensional**. Si has utilizado al menos 3\n",
    "variables en `features_kmeans`, puedes construir un mapa 3D donde:\n",
    "\n",
    "- Cada eje corresponde a una de las variables físicas usadas en K-Means.\n",
    "- Cada punto es un exoplaneta.\n",
    "- El color indica el cluster asignado.\n",
    "\n",
    "Esta vista sirve para comprobar si en tres dimensiones los grupos están aún más claros o si algunos clusters\n",
    "se solapan cuando añades una variable extra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80990292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista 3D – espacio original (sin escalar)\n",
    "\n",
    "if len(features_kmeans) >= 3:\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    x = df_km[features_kmeans[0]]\n",
    "    y = df_km[features_kmeans[1]]\n",
    "    z = df_km[features_kmeans[2]]\n",
    "    c = df_km[\"cluster_kmeans\"]\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x, y, z,\n",
    "        c=c,\n",
    "        cmap=\"tab10\",\n",
    "        s=30,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(features_kmeans[0])\n",
    "    ax.set_ylabel(features_kmeans[1])\n",
    "    ax.set_zlabel(features_kmeans[2])\n",
    "    ax.set_title(\"Clusters creados por K-Means (3D – espacio original)\")\n",
    "\n",
    "    handles, labels = scatter.legend_elements(prop=\"colors\", alpha=0.8)\n",
    "    ax.legend(handles, labels, title=\"Cluster\", loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Necesitas al menos 3 variables en features_kmeans para la vista 3D.\")\n",
    "\n",
    "#####\n",
    "# TAREA a comentar en tu informe:\n",
    "# - Interpreta la vista 3D: ¿se distinguen mejor los tipos de exoplanetas que en 2D?\n",
    "# - ¿Algún cluster parece muy extendido o mezclado con otros?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f53f4e",
   "metadata": {},
   "source": [
    "### 4.6 Visualización 3D de los clusters (espacio escalado)\n",
    "\n",
    "Aunque las gráficas anteriores usan los valores físicos originales, K-Means ha trabajado realmente en el\n",
    "**espacio escalado** (`X_km_scaled`).\n",
    "\n",
    "En esta sección vas a visualizar los clusters en ese espacio escalado:\n",
    "\n",
    "- Los ejes representan las versiones estandarizadas de las variables seleccionadas.\n",
    "- No tienen unidades físicas directas, pero reflejan la “posición relativa” de cada planeta respecto a la media.\n",
    "\n",
    "Esta vista te ayuda a entender **cómo “ve” el algoritmo** los exoplanetas, independientemente de sus unidades originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe09728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista 3D – espacio escalado (StandardScaler)\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "if len(features_kmeans) >= 3:\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Usamos directamente las tres primeras columnas del array escalado\n",
    "    x_scaled = X_km_scaled[:, 0]\n",
    "    y_scaled = X_km_scaled[:, 1]\n",
    "    z_scaled = X_km_scaled[:, 2]\n",
    "    c = df_km[\"cluster_kmeans\"].values\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        x_scaled, y_scaled, z_scaled,\n",
    "        c=c,\n",
    "        cmap=\"tab10\",\n",
    "        s=30,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(f\"{features_kmeans[0]} (scaled)\")\n",
    "    ax.set_ylabel(f\"{features_kmeans[1]} (scaled)\")\n",
    "    ax.set_zlabel(f\"{features_kmeans[2]} (scaled)\")\n",
    "    ax.set_title(\"Clusters creados por K-Means (3D – espacio escalado)\")\n",
    "\n",
    "    handles, labels = scatter.legend_elements(prop=\"colors\", alpha=0.8)\n",
    "    ax.legend(handles, labels, title=\"Cluster\", loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Necesitas al menos 3 variables en features_kmeans para la vista 3D escalada.\")\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Compara la vista 3D en espacio original y en espacio escalado.\n",
    "# - ¿Cambian las formas de los grupos o simplemente la escala?\n",
    "# - Explica en tu informe por qué el escalado es importante para K-Means,\n",
    "#   aunque las visualizaciones físicas te resulten más intuitivas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cdf77a",
   "metadata": {},
   "source": [
    "## 5. Diseño de la columna de clasificación\n",
    "\n",
    "Hasta ahora K-Means solo te ha dado **números de cluster** (`0`, `1`, `2`, …) sin significado físico. \n",
    "El Comité Científico de la Estación Kepler quiere algo más útil: una **propuesta de taxonomía de exoplanetas** que pueda usarse en futuros informes y misiones.\n",
    "\n",
    "Tu tarea en esta fase es convertir `cluster_kmeans` en una columna de **clasificación científica**,\n",
    "que llamaremos `tipo_planeta`. Esta decisión es tuya:\n",
    "\n",
    "- Asignar **nombres descriptivos** a cada cluster en función de lo que has visto en las gráficas y en función de las características propios de los exoplanetas.\n",
    "\n",
    "> Lo importante es que tu `tipo_planeta` tenga **sentido físico** y que puedas justificarlo en tu informe:\n",
    "> explica qué criterios has usado para nombrar/mezclar los clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994857d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_km.copy()\n",
    "\n",
    "# Diccionario para nombres de tipo de planeta\n",
    "mapa_tipos = { }\n",
    "\n",
    "if mapa_tipos:\n",
    "    df_model[\"tipo_planeta\"] = df_model[\"cluster_kmeans\"].map(mapa_tipos)\n",
    "else:\n",
    "    df_model[\"tipo_planeta\"] = df_model[\"cluster_kmeans\"].astype(str)\n",
    "\n",
    "print(\"Frecuencia de tipo_planeta:\")\n",
    "print(df_model[\"tipo_planeta\"].value_counts())\n",
    "\n",
    "#### TAREA:\n",
    "### - Declarar el Diccionario nuevo de los planetas clasificados en el cluster y justificar su elección en el INFORME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1392b",
   "metadata": {},
   "source": [
    "## 6. Preparación para modelos supervisados\n",
    "\n",
    "En este punto vas a usar `tipo_planeta` como etiqueta para entrenar modelos supervisados\n",
    "(árbol de decisión y SVM). Pero hay un problema potencial:\n",
    "\n",
    "- Si alguno de los tipos de planeta tiene **muy pocas muestras** (por ejemplo, 1 solo planeta),\n",
    "  el algoritmo `train_test_split` con `stratify=y` **no puede repartirlo** entre train y test y generará un error.\n",
    "\n",
    "Esto suele ocurrir cuando K-Means crea un **cluster “apropiado” por un outlier**: un planeta rarísimo se queda totalmente solo en su cluster.\n",
    "\n",
    "La tarea en esta sección es:\n",
    "\n",
    "1. Ver las **frecuencias de `tipo_planeta`** y detectar tipos con muy pocas muestras.\n",
    "2. Hacer un **primer intento de `train_test_split`** y observar el error, si existe.\n",
    "3. Diseñar una estrategia para **eliminar o reagrupar** esos tipos raros antes de entrenar los modelos supervisados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49db5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar cuántos planetas tiene cada tipo\n",
    "vc = df_model[\"tipo_planeta\"].value_counts()\n",
    "print(\"Frecuencia de cada tipo_planeta:\")\n",
    "print(vc)\n",
    "\n",
    "X = df_model[features_kmeans].values\n",
    "y = df_model[\"tipo_planeta\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=0.7,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Tamaño train:\", X_train.shape[0])\n",
    "print(\"Tamaño test :\", X_test.shape[0])\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Si este split te da error, copia el mensaje en tu informe y explica con tus palabras qué está pasando.\n",
    "# - ¿Qué tipo(s) de planeta son los sospechosos?\n",
    "# - Arregla el error para hacer una preparación correcta y deja reflejado en el informe cómo lo has hecho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcabef4e",
   "metadata": {},
   "source": [
    "## 7. Árbol de decisión – Autopiloto de clasificación\n",
    "\n",
    "Hasta ahora, K-Means ha servido como **módulo de descubrimiento** a bordo de la Estación Kepler: ha creado tipos de\n",
    "exoplanetas a partir de sus características físicas. Ahora el Comité quiere ir un paso más allá:\n",
    "\n",
    "> Entrenar un **autopiloto de clasificación** capaz de predecir el `tipo_planeta` de un nuevo exoplaneta usando solo\n",
    "> sus variables físicas.\n",
    "\n",
    "Para ello usarás un **árbol de decisión**:\n",
    "\n",
    "1. Probarás varias **profundidades** (`max_depth`) y compararás la `accuracy` de train y test.\n",
    "2. Elegirás una profundidad “razonable” (no solo la que más acierta en test, sino la que tenga sentido).\n",
    "3. Entrenarás un **árbol final** con esa profundidad.\n",
    "4. Analizarás su **matriz de confusión** y comentarás dónde se equivoca.\n",
    "\n",
    "Recuerda: estamos imitando la clasificación propuesta por K-Means. Si los clusters están muy bien separados, el árbol\n",
    "podría llegar a reconstruirlos casi perfectamente… o sobreajustar si lo hacemos demasiado profundo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de profundidades a probar\n",
    "depths = []\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "print(\"max_depth | acc_train | acc_test\")\n",
    "print(\"-\" * 32)\n",
    "\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_tr = clf.predict(X_train)\n",
    "    y_pred_te = clf.predict(X_test)\n",
    "\n",
    "    acc_tr = accuracy_score(y_train, y_pred_tr)\n",
    "    acc_te = accuracy_score(y_test, y_pred_te)\n",
    "\n",
    "    train_scores.append(acc_tr)\n",
    "    test_scores.append(acc_te)\n",
    "\n",
    "    print(f\"{str(d):>8} | {acc_tr:9.3f} | {acc_te:8.3f}\")\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Añade/quita valores en 'depths' y vuelve a ejecutar.\n",
    "# - Observa cómo cambian las accuracies de train y test.\n",
    "# - ¿Ves señales de sobreajuste (train muy alto y test bajando)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb8214",
   "metadata": {},
   "source": [
    "### 7.1 - Curva prfundidad vs accuract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = [str(d) if d is not None else \"None\" for d in depths]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(len(depths)), train_scores, marker=\"o\", label=\"Train\")\n",
    "plt.plot(range(len(depths)), test_scores, marker=\"o\", label=\"Test\")\n",
    "plt.xticks(range(len(depths)), x_labels)\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Profundidad del árbol vs Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# best_depth =\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Mira la gráfica y el cuadro de valores anterior.\n",
    "# - Elige MANUALMENTE una profundidad 'best_depth' que consideres razonable:\n",
    "#   * ¿Te quedarías con la que más test tiene o con una un poco más simple pero con test similar?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfdde6",
   "metadata": {},
   "source": [
    "### 7.2 - Entrenamiento del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25466c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = DecisionTreeClassifier(max_depth=, random_state=)\n",
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = best_tree.predict(X_train)\n",
    "y_pred_test = best_tree.predict(X_test)\n",
    "\n",
    "acc_tr_final = accuracy_score(y_train, y_pred_train)\n",
    "acc_te_final = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Árbol final con max_depth = {best_depth}\")\n",
    "print(f\"Accuracy (train): {acc_tr_final:.3f}\")\n",
    "print(f\"Accuracy (test) : {acc_te_final:.3f}\")\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Justifica en tu informe por qué has elegido este 'best_depth' en lugar de otros posibles.\n",
    "# - Comenta si el modelo parece estar sobreajustando o no."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab4db1",
   "metadata": {},
   "source": [
    "#### 7.2.1: Visualización del árbol: Figura\n",
    "\n",
    "En este paso, inspeccionarás el **árbol de decisión final** como si fuera\n",
    "el diagrama lógico del ordenador central de la Estación Kepler.\n",
    "\n",
    "Queremos ver:\n",
    "\n",
    "- Qué variables físicas aparecen en los primeros niveles.\n",
    "- Qué umbrales usa el árbol para separar los tipos de exoplanetas.\n",
    "- Si el árbol es relativamente sencillo o se ha convertido en una “selva” difícil de interpretar.\n",
    "\n",
    "Para ello, dibujarás el árbol entrenado con `best_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los nombres de tus clases\n",
    "class_names = []\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_tree(\n",
    "    best_tree,\n",
    "    feature_names=features_kmeans,   # variables usadas como entrada del modelo\n",
    "    class_names=class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8\n",
    ")\n",
    "plt.title(f\"Árbol de decisión final (max_depth={best_depth})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Identifica qué variables aparecen en los primeros niveles del árbol.\n",
    "# - Comenta si coinciden con tu intuición física (por ejemplo, ¿usa mucho la masa?).\n",
    "# - Explica en tu informe, con palabras, una o dos ramas del árbol: “Si el periodo orbital es menor que X y la masa es mayor que Y, el sistema clasifica el planeta como tipo Z…”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6e7b3",
   "metadata": {},
   "source": [
    "#### 7.2.2: Visualización del árbol: Regiones 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7514ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Elige las DOS características que quieres usar en 2D\n",
    "#    Deben estar dentro de features_kmeans\n",
    "FEAT_X = features_kmeans[0]   # Cámbialo si quieres usar otra variable en el eje X\n",
    "FEAT_Y = features_kmeans[1]   # Cámbialo si quieres usar otra variable en el eje Y\n",
    "\n",
    "print(\"Usaremos para la vista 2D:\")\n",
    "print(\"  Eje X:\", FEAT_X)\n",
    "print(\"  Eje Y:\", FEAT_Y)\n",
    "\n",
    "# Posiciones de esas columnas dentro de X_train / X_test\n",
    "idx_x = features_kmeans.index(FEAT_X)\n",
    "idx_y = features_kmeans.index(FEAT_Y)\n",
    "\n",
    "# Creamos versiones 2D de los conjuntos\n",
    "X_train_2d = X_train[:, [idx_x, idx_y]]\n",
    "X_test_2d  = X_test[:,  [idx_x, idx_y]]\n",
    "\n",
    "print(\"Shape X_train_2d:\", X_train_2d.shape)\n",
    "print(\"Shape X_test_2d :\", X_test_2d.shape)\n",
    "\n",
    "\n",
    "def plot_decision_regions_2d(model, X, y, feat_x_name, feat_y_name, title='Regiones de decisión'):\n",
    "    \"\"\"\n",
    "    Dibuja las regiones de decisión de un clasificador en 2D (multiclase).\n",
    "    \"\"\"\n",
    "    # Convertimos las etiquetas (posiblemente strings) a enteros para poder colorear\n",
    "    clases = np.unique(y)\n",
    "    mapa_clase_a_int = {cl: i for i, cl in enumerate(clases)}\n",
    "    \n",
    "    y_int = np.array([mapa_clase_a_int[cl] for cl in y])\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 300),\n",
    "        np.linspace(y_min, y_max, 300)\n",
    "    )\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # Predicción sobre la rejilla\n",
    "    Z = model.predict(grid)\n",
    "    Z_int = np.array([mapa_clase_a_int[cl] for cl in Z]).reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Fondo de regiones\n",
    "    plt.contourf(xx, yy, Z_int, alpha=0.25)\n",
    "\n",
    "    # Puntos reales\n",
    "    for cl in clases:\n",
    "        mask = (y == cl)\n",
    "        plt.scatter(\n",
    "            X[mask, 0],\n",
    "            X[mask, 1],\n",
    "            label=str(cl),\n",
    "            edgecolor='k',\n",
    "            alpha=0.85,\n",
    "            s=30\n",
    "        )\n",
    "\n",
    "    plt.xlabel(feat_x_name)\n",
    "    plt.ylabel(feat_y_name)\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"tipo_planeta\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Entrenamos un árbol SOLO con las dos variables seleccionadas\n",
    "tree_2d = DecisionTreeClassifier(max_depth=best_depth, random_state=42)\n",
    "tree_2d.fit(X_train_2d, y_train)\n",
    "\n",
    "# Regiones de decisión en el conjunto de entrenamiento\n",
    "plot_decision_regions_2d(\n",
    "    tree_2d,\n",
    "    X_train_2d,\n",
    "    y_train,\n",
    "    feat_x_name=FEAT_X,\n",
    "    feat_y_name=FEAT_Y,\n",
    "    title=f\"Regiones de decisión (train) – Árbol 2D (max_depth={best_depth})\"\n",
    ")\n",
    "\n",
    "# Regiones de decisión en el conjunto de test\n",
    "plot_decision_regions_2d(\n",
    "    tree_2d,\n",
    "    X_test_2d,\n",
    "    y_test,\n",
    "    feat_x_name=FEAT_X,\n",
    "    feat_y_name=FEAT_Y,\n",
    "    title=f\"Regiones de decisión (test) – Árbol 2D (max_depth={best_depth})\"\n",
    ")\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Cambia FEAT_X y FEAT_Y para ver otras combinaciones de variables.\n",
    "# - Compara visualmente las regiones en train y en test: ¿Ves fronteras muy retorcidas en train que luego no encajan bien en test? ¿Algún tipo de planeta queda en una “isla” pequeña rodeada de otros?\n",
    "# - Explica en tu informe qué te dicen estas figuras sobre el comportamiento del autopiloto de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250f2a8",
   "metadata": {},
   "source": [
    "### 7.3 - Matriz de confusión y análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = best_tree.predict(X_test)\n",
    "labels = sorted(np.unique(y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_best, labels=labels)\n",
    "\n",
    "# Matriz de confusión en valores absolutos\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=, display_labels=labels)\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(f\"Matriz de confusión – Árbol de decisión (max_depth={best_depth})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusión en porcentajes por fila (respecto a la clase real)\n",
    "cm_pct = cm / cm.sum(axis=1, keepdims=True)\n",
    "cm_pct_round = np.round(cm_pct * 100, 2)\n",
    "\n",
    "print(\"Matriz de confusión en porcentajes (por fila – clase real):\")\n",
    "print(cm_pct_round)\n",
    "\n",
    "print(\"\\nInforme de clasificación (precision, recall, f1 por tipo de planeta):\")\n",
    "print(classification_report(y_test, y_pred_best, digits=3))\n",
    "\n",
    "#####\n",
    "# TAREA:\n",
    "# - Identifica qué tipos de planeta se confunden más entre sí.\n",
    "# - ¿Hay algún tipo que el árbol casi nunca acierta o que casi siempre acierte?\n",
    "# - Relaciona esto con lo que viste en los gráficos de K-Means ¿Esos tipos estaban cerca en el espacio de características?\n",
    "# - Incluye en tu informe una breve discusión del tipo: “El autopiloto de clasificación de la Estación Kepler tiende a …”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132a959",
   "metadata": {},
   "source": [
    "## 8. SVM: kernels lineal, polinómico y RBF\n",
    "\n",
    "El Comité de Navegación de la Estación Kepler-Σ quiere comparar el árbol de decisión con otro tipo de\n",
    "autopiloto de clasificación: las **Máquinas de Vectores Soporte (SVM)**.\n",
    "\n",
    "La idea es entrenar tres modelos distintos usando solo dos variables físicas\n",
    "(`FEAT_X` y `FEAT_Y`, las mismas que has usado en las regiones de decisión del árbol):\n",
    "\n",
    "- SVM con **kernel lineal**  \n",
    "- SVM con **kernel polinómico**  \n",
    "- SVM con **kernel RBF**  \n",
    "\n",
    "Para cada kernel deberás:\n",
    "\n",
    "1. Entrenar una SVM sobre el conjunto `X_train_2d, y_train`.\n",
    "2. Calcular la **accuracy en test**.\n",
    "3. Dibujar las **regiones de decisión** en train y en test.\n",
    "4. Mostrar la **matriz de confusión** (normalizada por filas) y comentar sus errores.\n",
    "\n",
    "> Tu objetivo es decidir cuál de los tres kernels se comporta mejor como autopiloto de clasificación de\n",
    "> exoplanetas en este espacio 2D, y explicar **por qué crees que ese kernel funciona mejor o peor**\n",
    "> (fronteras lineales vs curvas, sobreajuste, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb04c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declara los kernels\n",
    "kernels = []\n",
    "resultados_svm = {}\n",
    "\n",
    "# Orden de etiquetas para las matrices de confusión\n",
    "labels = sorted(np.unique(y_test))\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"SVM con kernel = {kernel}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Pipeline: escalado + SVM\n",
    "    # Cambia C, degree o gamma\n",
    "    svm_clf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel=kernel, C= degree=, gamma=\"scale\", random_state=42)\n",
    "    )\n",
    "\n",
    "    # Entrenamos usando solo las dos variables elegidas (vista 2D)\n",
    "    svm_clf.fit(X_train_2d, y_train)\n",
    "\n",
    "    # Predicción en test\n",
    "    y_pred = svm_clf.predict(X_test_2d)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    resultados_svm[kernel] = acc\n",
    "\n",
    "    print(f\"Accuracy en test: {acc:.3f}\")\n",
    "    print(\"\\nInforme de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "    # Regiones de decisión en el conjunto de entrenamiento\n",
    "    plot_decision_regions_2d(\n",
    "        svm_clf,\n",
    "        X_train_2d,\n",
    "        y_train,\n",
    "        feat_x_name=FEAT_X,\n",
    "        feat_y_name=FEAT_Y,\n",
    "        title=f\"Regiones de decisión (TRAIN) – SVM ({kernel})\"\n",
    "    )\n",
    "\n",
    "    # Regiones de decisión en el conjunto de test\n",
    "    plot_decision_regions_2d(\n",
    "        svm_clf,\n",
    "        X_test_2d,\n",
    "        y_test,\n",
    "        feat_x_name=FEAT_X,\n",
    "        feat_y_name=FEAT_Y,\n",
    "        title=f\"Regiones de decisión (TEST) – SVM ({kernel})\"\n",
    "    )\n",
    "\n",
    "    # Matriz de confusión normalizada por filas\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        cm_norm,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"magma\",\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels\n",
    "    )\n",
    "    plt.xlabel(\"Predicción SVM\")\n",
    "    plt.ylabel(\"Tipo real\")\n",
    "    plt.title(f\"Matriz de confusión – SVM ({kernel})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Resumen final\n",
    "print(\"\\nResumen de accuracy en test por kernel:\")\n",
    "for k, v in resultados_svm.items():\n",
    "    print(f\"- {k:6s}: {v:.3f}\")\n",
    "\n",
    "#####\n",
    "# TAREAS:\n",
    "# 1) Cambia FEAT_X y FEAT_Y para probar otros pares de variables físicas.\n",
    "# 2) Vuelve a ejecutar esta celda y compara cómo cambian las fronteras y las matrices de confusión.\n",
    "# 3) Prueba a modificar C, degree (para 'poly') o gamma (para 'rbf') en la definición de SVC.\n",
    "# 4) En tu informe responde:\n",
    "#    - ¿Qué kernel funciona mejor en tu escenario? ¿Por qué?\n",
    "#    - ¿Qué kernel parece sobreajustar más (fronteras muy retorcidas, errores raros en test, etc)?\n",
    "#    - ¿Tiene sentido físico el tipo de frontera que dibuja cada kernel para separar los tipos de exoplanetas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae42dc6",
   "metadata": {},
   "source": [
    "## 9. Guía para el informe en Word\n",
    "\n",
    "En el informe final deberías incluir, al menos:\n",
    "\n",
    "1. **Objetivo y contexto**: misión científica y qué quieres conseguir.\n",
    "2. **Selección de variables**: qué columnas has usado y por qué.\n",
    "3. **K-Means**: elección de K, interpretación de cada cluster, posibles outliers.\n",
    "4. **Árbol de decisión**: profundidad elegida, comparación train/test, matriz de confusión.\n",
    "5. **SVM**: comparación entre kernels (linear, poly, rbf). ¿Cuál se ajusta mejor y por qué?\n",
    "6. **Conclusiones**: qué has aprendido sobre los tipos de exoplanetas y sobre las diferencias entre aprendizaje no supervisado y supervisado.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

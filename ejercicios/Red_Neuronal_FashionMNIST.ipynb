{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bca994b",
   "metadata": {},
   "source": [
    "# Hello World de Redes Neuronales con Keras\n",
    "\n",
    "Objetivos de este cuaderno:\n",
    "- Entender visualmente las funciones de activación más típicas.\n",
    "- Cargar un dataset real que ya viene en Keras (Fashion MNIST).\n",
    "- Construir una red neuronal completamente conectada (sin convoluciones).\n",
    "- Probar a cambiar optimizadores, funciones de pérdida, funciones de activación, etc.\n",
    "\n",
    "Más info: https://www.tensorflow.org/datasets/catalog/fashion_mnist?hl=es\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a6e8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Si te da error, prueba a hacer el pip install a las librerías que te fallen\n",
    "import tensorflow as tf\n",
    "import keras                     \n",
    "\n",
    "# Para que los gráficos se vean más bonitos\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03b669",
   "metadata": {},
   "source": [
    "## 1. Visualizando funciones de activación\n",
    "\n",
    "Vamos a dibujar algunas funciones de activación:\n",
    "\n",
    "- Sigmoid\n",
    "- ReLU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05099dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "\n",
    "# Activaciones\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(z, sigmoid(z), \"g--\", linewidth=2, label=\"Sigmoid\")\n",
    "plt.plot(z, relu(z), \"m-.\", linewidth=2, label=\"ReLU\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"center right\", fontsize=10)\n",
    "plt.title(\"Funciones de activación\", fontsize=12)\n",
    "plt.axis([-5, 5, -1.2, 1.2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f4eefc",
   "metadata": {},
   "source": [
    "## 2. Cargando el dataset de Keras: Fashion MNIST\n",
    "\n",
    "Fashion MNIST es como el clásico MNIST de números, pero con ropa:\n",
    "Características principales:\n",
    "\n",
    "- **Tipo de dato:** imágenes en escala de grises.\n",
    "- **Tamaño de cada imagen:** 28 × 28 píxeles.\n",
    "- **Forma en memoria:** una matriz 2D de 28 filas × 28 columnas, donde cada número indica cuánta “tinta” hay en ese píxel (0 = negro, 255 = blanco).\n",
    "- **Número de clases:** 10 tipos de prendas diferentes.\n",
    "- **Número de ejemplos:**\n",
    "  - 60.000 imágenes de entrenamiento.\n",
    "  - 10.000 imágenes de test.\n",
    "\n",
    "Las 10 clases de Fashion MNIST son:\n",
    "\n",
    "- 0 → Camiseta/Top  \n",
    "- 1 → Pantalón  \n",
    "- 2 → Jersey  \n",
    "- 3 → Vestido  \n",
    "- 4 → Abrigo  \n",
    "- 5 → Sandalia  \n",
    "- 6 → Camisa  \n",
    "- 7 → Zapatilla deportiva  \n",
    "- 8 → Bolso  \n",
    "- 9 → Bota  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f90412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset directamente desde Keras\n",
    "(fashion_x_train, fashion_y_train), (fashion_x_test, fashion_y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "print(\"Tamaño de x_train:\", fashion_x_train.shape)\n",
    "print(\"Tamaño de y_train:\", fashion_y_train.shape)\n",
    "print(\"Tamaño de x_test:\", fashion_x_test.shape)\n",
    "print(\"Tamaño de y_test:\", fashion_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d66cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetas de las clases para mostrar los nombres\n",
    "class_names = [\n",
    "    \"Camiseta/Top\", \"Pantalón\", \"Jersey\", \"Vestido\",\n",
    "    \"Abrigo\", \"Sandalia\", \"Camisa\", \"Zapatilla\",\n",
    "    \"Bolso\", \"Bota\"\n",
    "]\n",
    "\n",
    "# Visualizamos algunos ejemplos\n",
    "plt.figure(figsize=(9, 9))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(fashion_x_train[i], cmap=\"gray\")\n",
    "    label = fashion_y_train[i]\n",
    "    plt.title(f\"{class_names[label]} ({label})\", fontsize=9)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711e88d4",
   "metadata": {},
   "source": [
    "## 3. Preparar los datos para la red neuronal\n",
    "\n",
    "Pasos:\n",
    "- Escalar los píxeles a valores entre 0 y 1.\n",
    "- \"Aplanar\" las imágenes 28x28 a vectores de 784 componentes.\n",
    "- Separar un pequeño conjunto de validación a partir de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2df448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización: de [0, 255] a [0, 1]\n",
    "x_train = fashion_x_train.astype(\"float32\") / 255.0\n",
    "x_test = fashion_x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Aplanamos: (num_imágenes, 28, 28) -> (num_imágenes, 784)\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "print(\"Nueva forma de x_train:\", x_train.shape)\n",
    "print(\"Nueva forma de x_test:\", x_test.shape)\n",
    "\n",
    "# Creamos un conjunto de validación sencillo\n",
    "# (por ejemplo, las primeras 5.000 muestras para validación)\n",
    "x_val = x_train[:5000]\n",
    "y_val = fashion_y_train[:5000]\n",
    "\n",
    "x_train_small = x_train[5000:]\n",
    "y_train_small = fashion_y_train[5000:]\n",
    "\n",
    "print(\"x_train_small:\", x_train_small.shape)\n",
    "print(\"x_val:\", x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70bcd0",
   "metadata": {},
   "source": [
    "## 4. Definir la arquitectura de la red\n",
    "\n",
    "Vamos a crear una red totalmente conectada con Keras:\n",
    "\n",
    "- Capa de entrada: 784 neuronas (los 28x28 píxeles aplanados).\n",
    "- Una o dos capas ocultas con activación ReLU.\n",
    "- Capa de salida con 10 neuronas y `activation=\"softmax\"` (10 clases).\n",
    "\n",
    "Tenéis que probar a:\n",
    "- Cambiar el número de neuronas en las capas.\n",
    "- Cambiar la función de activación de las capas ocultas.\n",
    "- Cambiar la activación de la capa de salida (softmax ↔ otras según el problema).\n",
    "- Cambiar el optimizador y la función de pérdida más abajo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train_small.shape[1]\n",
    "n_classes = 10\n",
    "\n",
    "# Hiperparámetros \"fáciles de tocar\" por el alumno\n",
    "hidden_units_1 = 128\n",
    "hidden_units_2 = 64      # puedes poner None si quieres quitar esta capa\n",
    "activation_hidden = \"relu\"  # prueba con \"sigmoid\", \"tanh\", etc.\n",
    "activation_output = \"softmax\"  # en clasificación multiclase, softmax es lo estándar\n",
    "\n",
    "# Definimos el modelo Sequential (pila lineal de capas)\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Capa de entrada + primera capa oculta\n",
    "model.add(layers.Input(shape=(n_features,)))\n",
    "model.add(layers.Dense(hidden_units_1, activation=activation_hidden))\n",
    "\n",
    "# Segunda capa oculta opcional\n",
    "if hidden_units_2 is not None:\n",
    "    model.add(layers.Dense(hidden_units_2, activation=activation_hidden))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(layers.Dense(n_classes, activation=activation_output))\n",
    "\n",
    "# Mostramos el resumen\n",
    "model.summary()\n",
    "\n",
    "# Dibujamos el modelo a un archivo PNG\n",
    "# (si da error, puede que falte instalar graphviz/pydot en tu entorno)\n",
    "plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f001170",
   "metadata": {},
   "source": [
    "## 5. Compilar el modelo: optimizador, función de pérdida y métricas\n",
    "\n",
    "Aquí respondemos a varias preguntas típicas:\n",
    "\n",
    "- **¿Qué es el optimizador?**  \n",
    "  Es el algoritmo que actualiza los pesos de la red para minimizar la pérdida.\n",
    "  Ejemplos: `\"sgd\"`, `\"adam\"`, `\"rmsprop\"`, etc.\n",
    "\n",
    "- **¿Qué es la función de pérdida (`loss`)?**  \n",
    "  Es la medida de \"error\" que el modelo intenta minimizar.  \n",
    "  Para clasificación multiclase con etiquetas 0,1,2… se suele usar\n",
    "  `\"sparse_categorical_crossentropy\"`.\n",
    "\n",
    "- **¿Qué son las métricas (`metrics`)?**  \n",
    "  Son indicadores para monitorizar el rendimiento (por ejemplo, `accuracy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d96ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puedes cambiar estos valores y volver a entrenar para ver qué pasa\n",
    "optimizer_name = \"adam\"  # prueba con \"sgd\", \"rmsprop\", \"adamax\", etc.\n",
    "loss_name = \"sparse_categorical_crossentropy\"  # problema de clasificación multiclase\n",
    "metrics_list = [\"accuracy\"]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer_name,\n",
    "    loss=loss_name,\n",
    "    metrics=metrics_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e0217",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento del modelo\n",
    "\n",
    "Aquí aparecen conceptos importantes:\n",
    "\n",
    "- **epochs**: cuántas veces ve el modelo TODO el conjunto de entrenamiento.\n",
    "- **batch_size**: número de ejemplos que se usan en cada actualización de pesos.\n",
    "- **validation_data**: datos con los que comprobamos si el modelo se está sobreajustando.\n",
    "- **verbose**:\n",
    "  - `0` → no muestra nada.\n",
    "  - `1` → barra de progreso (suele ser el más cómodo).\n",
    "  - `2` → una línea por epoch, más compacto.\n",
    "\n",
    "Juega con estos parámetros para ver cómo cambia el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10       # prueba con 5, 10, 20...\n",
    "batch_size = 32   # prueba con 16, 64...\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_small, y_train_small,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec3a60",
   "metadata": {},
   "source": [
    "## 7. Visualizar la evolución del entrenamiento\n",
    "\n",
    "Vamos a dibujar:\n",
    "- La pérdida de entrenamiento y validación por epoch.\n",
    "- La accuracy de entrenamiento y validación por epoch (si está disponible).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236275db",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "# Pérdida (loss)\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict[\"loss\"], label=\"Train loss\")\n",
    "plt.plot(history_dict[\"val_loss\"], label=\"Val loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Pérdida durante el entrenamiento\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Accuracy (si existe)\n",
    "if \"accuracy\" in history_dict:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_dict[\"accuracy\"], label=\"Train acc\")\n",
    "    plt.plot(history_dict[\"val_accuracy\"], label=\"Val acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy durante el entrenamiento\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba363f2",
   "metadata": {},
   "source": [
    "## 8. Evaluar en el conjunto de test\n",
    "\n",
    "Ahora evaluamos el modelo final sobre datos que no se han usado ni para entrenar\n",
    "ni para validar: el conjunto de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a969bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, fashion_y_test, verbose=0)\n",
    "print(f\"Pérdida en test: {test_loss:.4f}\")\n",
    "print(f\"Accuracy en test: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928c16b",
   "metadata": {},
   "source": [
    "### 8.1. Probar la Red Neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab931c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar la red neuronal con una imagen concreta del conjunto de test\n",
    "\n",
    "# 1. Cambia este índice (0, 1, 2, ..., len(x_test)-1) => Este índice es la imagen que quieres meter en tu red neuronal\n",
    "idx = 0  # prueba con 0, 10, 1234, etc.\n",
    "\n",
    "# 2. Preparamos la imagen para el modelo\n",
    "#    - x_test ya está normalizado y aplanado (shape: [num_imágenes, 784])\n",
    "img_para_modelo = x_test[idx].reshape(1, -1)  # (1, 784)\n",
    "\n",
    "# 3. Hacemos la predicción\n",
    "pred_probs = model.predict(img_para_modelo)\n",
    "pred_clase = np.argmax(pred_probs, axis=1)[0]\n",
    "\n",
    "# 4. Obtenemos la etiqueta real\n",
    "true_clase = fashion_y_test[idx]\n",
    "\n",
    "print(f\"Índice de la imagen: {idx}\")\n",
    "print(f\"Etiqueta real     => {true_clase} ({class_names[true_clase]})\")\n",
    "print(f\"Predicción modelo => {pred_clase} ({class_names[pred_clase]})\")\n",
    "\n",
    "# 5. Mostramos la imagen original en 28x28\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(fashion_x_test[idx], cmap=\"gray\")\n",
    "plt.title(f\"Real: {class_names[true_clase]}\\nPred: {class_names[pred_clase]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df530c88",
   "metadata": {},
   "source": [
    "## 9. Ejercicios propuestos para trastear\n",
    "\n",
    "Usa este cuaderno como \"laboratorio\" y prueba a modificar lo siguiente:\n",
    "\n",
    "1. **Capas y neuronas**\n",
    "   - Cambia `hidden_units_1` y `hidden_units_2`.\n",
    "   - Añade una tercera capa oculta.\n",
    "\n",
    "2. **Funciones de activación**\n",
    "   - Cambia `activation_hidden` a `\"sigmoid\"` o `\"tanh\"`.\n",
    "   - Observa si el entrenamiento va más lento o si cambia la accuracy.\n",
    "\n",
    "3. **Optimizadores**\n",
    "   - Cambia `optimizer_name` a `\"sgd\"`, `\"rmsprop\"`, `\"adamax\"`, etc.\n",
    "   - Compara la velocidad y el rendimiento final.\n",
    "\n",
    "4. **Funciones de pérdida**\n",
    "   - Piensa: ¿qué pasaría si usara una `loss` de regresión aquí? ¿tendría sentido?\n",
    "\n",
    "5. **Parámetros de entrenamiento**\n",
    "   - Cambia `epochs` y `batch_size`.\n",
    "   - Observa si el modelo sobreajusta (train muy bien, val/test peor)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>T√©cnicas avanzadas y evaluaci√≥n del modelo</title>
  <!-- MISMO CSS BASE (unidad3.html) + peque√±as extensiones -->
  <style>
:root {
      --fg: #111827; /* slate-900 */
      --muted: #4b5563; /* gray-600 */
      --bg: #ffffff;
      --brand: #0ea5e9; /* sky-500 */
      --brand-ink: #075985; /* sky-800 */
      --card: #f8fafc; /* slate-50 */
      --code: #111827; /* slate-900 */
      --border: #e5e7eb; /* gray-200 */
      /* accent */
      --h1: #1d4ed8; /* blue-700 */
      --h2: #6d28d9; /* violet-700 */
      --h3: #0284c7; /* sky-600 */
      --section-underline: #dbeafe; /* blue-100 */
      --divider: #e5e7eb; /* gray-200 */
    }
    html, body { background: var(--bg); color: var(--fg); font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; }
    .page { max-width: 920px; margin: auto; padding: 2rem 1.25rem 6rem; line-height: 1.65; }
    header h1 { font-size: clamp(1.6rem, 2.5vw + 1rem, 2.4rem); margin: 0 0 .25rem; color: var(--h1); letter-spacing: -0.01em; }
    header p.lead { color: var(--muted); margin: 0 0 1.25rem; }
    .breadcrumbs { font-size: .9rem; color: var(--muted); margin-bottom: .5rem; }
    .breadcrumbs a { color: var(--muted); text-decoration: none; }
    nav.toc { background: var(--card); border: 1px solid var(--border); border-radius: .75rem; padding: 1rem; margin: 1.25rem 0 2rem; }
    nav.toc strong { display: block; margin-bottom: .5rem; }
    nav.toc a { display: block; color: var(--brand-ink); text-decoration: none; padding: .25rem 0; }
    h2 { margin-top: 2.25rem; font-size: 1.6rem; color: var(--h2); padding-bottom: .35rem; border-bottom: 1px solid var(--section-underline); }
    h3 { margin-top: 1.5rem; font-size: 1.25rem; color: var(--h3); }
    .page section + section { border-top: 1px solid var(--divider); margin-top: 2.25rem; padding-top: 2rem; }
    .note { background: #ecfeff; border-left: 4px solid var(--brand); padding: .75rem 1rem; border-radius: .5rem; }
    .card { background: var(--card); border: 1px solid var(--border); border-radius: .75rem; padding: 1rem; }
    code, pre { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font-size: .95em; }
    pre { background: #0b1020; color: #e2e8f0; border-radius: .5rem; padding: 1rem; overflow: auto; }
    .pill { display: inline-block; border: 1px solid var(--border); border-radius: 999px; padding: .1rem .6rem; font-size: .875rem; color: var(--muted); background: #fff; }
    details { border: 1px solid var(--border); border-radius: .5rem; padding: .75rem 1rem; background: #fff; }
    details + details { margin-top: .75rem; }
    footer { margin-top: 3rem; font-size: .9rem; color: var(--muted); }
    .top { position: fixed; right: 1rem; bottom: 1rem; background: var(--brand); color: #fff; border-radius: 999px; padding: .6rem .8rem; text-decoration: none; box-shadow: 0 6px 18px rgba(2,132,199,.3); }
    figure.media { margin: 1rem 0 1.25rem; }
    figure.media img { max-width: 100%; height: auto; display: block; border-radius: .5rem; }
    figure.media figcaption { margin-top: .5rem; text-align: center; color: var(--muted); font-size: .95rem; }

    /* Extras a√±adidos para mantener el mismo look & feel y cubrir clases usadas en los apuntes */
    .grid-2 { display: grid; grid-template-columns: 1fr; gap: 1rem; align-items: start; }
    @media (min-width: 780px) { .grid-2 { grid-template-columns: 1fr 1fr; } }
    .tabla-simple { width: 100%; border-collapse: collapse; margin: .75rem 0 1rem; font-size: .95rem; }
    .tabla-simple th, .tabla-simple td { border: 1px solid var(--border); padding: .5rem .6rem; vertical-align: top; }
    .tabla-simple th { background: #ffffff; color: var(--brand-ink); text-align: left; }
    .tips-box { background: #fefce8; border: 1px solid #fde68a; border-left: 4px solid #f59e0b; padding: .75rem 1rem; border-radius: .5rem; margin: 1rem 0; }
    .img-placeholder { border: 2px dashed var(--border); border-radius: .75rem; padding: 1.25rem; text-align: center; color: var(--muted); background: #fff; }
    .img-placeholder strong { color: var(--fg); display: block; margin-bottom: .25rem; }
    .kpi { display: inline-block; background: #fff; border: 1px solid var(--border); border-radius: .75rem; padding: .5rem .75rem; margin: .25rem .25rem 0 0; }
    .kpi b { color: var(--fg); }

  </style>
</head>
<body>
  <div class="page">
    <header id="top">
      <div class="breadcrumbs">Sistemas de Aprendizaje Autom√°tico ‚Üí Tema 3 (continuaci√≥n)</div>
      <h1>T√©cnicas avanzadas y evaluaci√≥n del modelo</h1>
      <p class="lead">
        Apuntes pr√°cticos para: <span class="pill">validaci√≥n cruzada</span> ¬∑ <span class="pill">optimizaci√≥n de hiperpar√°metros</span> ¬∑
        <span class="pill">desbalanceo</span> ¬∑ <span class="pill">anomal√≠as</span>
      </p>
      <figure class="card">
        <img src="../img/SAA05_MapaConceptual.png" alt="Mapa Conceptual" loading="lazy" decoding="async">
        <figcaption>Mapa Conceptual.</figcaption>
      </figure>
    </header>

    <nav class="toc" aria-label="Tabla de contenidos">
      <strong>√çndice de la p√°gina</strong>
      <a href="#eval">1. Evaluaci√≥n del modelo</a>
      <a href="#cv">1.1. Validaci√≥n cruzada</a>
      <a href="#cv-kfold">1.1.1. Validaci√≥n cruzada de K iteraciones (K-Fold)</a>
      <a href="#cv-random">1.1.2. Validaci√≥n cruzada aleatoria</a>
      <a href="#cv-loo">1.1.3. Validaci√≥n cruzada dejando uno fuera (Leave-One-Out)</a>
      <a href="#hpo">2. Optimizaci√≥n de hiperpar√°metros</a>
      <a href="#hpo-idea">2.1. Qu√© se est√° optimizando</a>
      <a href="#random-search">2.2. B√∫squeda aleatoria (Random Search)</a>
      <a href="#grid-search">2.3. B√∫squeda en cuadr√≠cula (Grid Search)</a>
      <a href="#hpo-tips">2.4. Consejos pr√°cticos</a>
      <a href="#imbalance">3. Desbalanceo y anomal√≠as</a>
      <a href="#imbalance-ds">3.1. Dataset desbalanceado</a>
      <a href="#undersampling">3.1.1. Submuestreo (Under-sampling)</a>
      <a href="#oversampling">3.1.2. Sobremuestreo (Over-sampling + SMOTE)</a>
      <a href="#other-strats">3.1.3. Otras estrategias</a>
      <a href="#anomalies">3.2. Detecci√≥n de anomal√≠as</a>
      <a href="#pca-ae">3.2.1. PCA y autoencoders</a>
      <a href="#iforest">3.2.2. Isolation Forest</a>
      <a href="#anomaly-tips">3.2.3. Consejos de evaluaci√≥n</a>
    </nav>

    
    <!-- 1 -->
    <section id="eval">
      <h2>1. Evaluaci√≥n del modelo</h2>
      <div class="note">
        <strong>En estos apuntes empezamos en 1.1 (Validaci√≥n cruzada).</strong>
        Se omite el apartado previo sobre los par√°metros de la matriz de confusi√≥n.
      </div>
    </section>

    <!-- 1.1 -->
    <section id="cv">
      <h2>1.1. Validaci√≥n cruzada</h2>

      <p>
        La validaci√≥n cruzada consiste en <strong>repetir</strong> el proceso de entrenamiento y evaluaci√≥n
        sobre <strong>particiones distintas</strong> del mismo dataset. En vez de un solo resultado,
        obtenemos varios, que suelen resumirse como:
      </p>

      <div class="kpi"><b>score medio</b> (estimaci√≥n t√≠pica)</div>
      <div class="kpi"><b>desviaci√≥n</b> (qu√© tan estable es)</div>

      <div class="card" style="margin-top:1rem;">
        <figure class="media">
        <img src="../img/tema3-aplicaciones.JPG" alt="Ejemplos visuales de aplicaciones de redes neuronales" loading="lazy" decoding="async">
        <figcaption>Ejemplos de uso de redes neuronales.</figcaption>
      </figure>
      </div>

      <h3>¬øPor qu√© se usa?</h3>
      <ul>
        <li><strong>Menos dependencia</strong> del split concreto (mejor estimaci√≥n).</li>
        <li><strong>Comparar modelos</strong> de forma m√°s justa.</li>
        <li><strong>Seleccionar hiperpar√°metros</strong> con menos riesgo de ‚Äúoptimizar para un split‚Äù.</li>
      </ul>

      <h3>¬øQu√© devuelve?</h3>
      <ul>
        <li>Un conjunto de puntuaciones (una por iteraci√≥n / fold).</li>
        <li>Normalmente reportamos: <strong>media ¬± desviaci√≥n</strong>.</li>
      </ul>

      <details>
        <summary><strong>Autoevaluaci√≥n</strong> (r√°pida)</summary>
        <p>Si tu score cambia much√≠simo entre folds, ¬øqu√© te est√° diciendo sobre tu modelo o tus datos?</p>
        <ul>
          <li>Puede haber <strong>pocas muestras</strong>.</li>
          <li>Puede haber <strong>mucha varianza</strong> en la distribuci√≥n (datos heterog√©neos).</li>
          <li>Puede haber <strong>desbalanceo</strong> o clases raras.</li>
          <li>Puede que el modelo sea <strong>inestable</strong> (muy complejo para el dataset).</li>
        </ul>
      </details>
    </section>

    <!-- 1.1.1 -->
    <section id="cv-kfold">
      <h2>1.1.1. Validaci√≥n cruzada de K iteraciones (K-Fold)</h2>

      <p>
        En <strong>K-Fold</strong>, dividimos el dataset en <strong>K partes</strong> (folds). Hacemos K iteraciones:
        en cada una, <strong>1 fold</strong> act√∫a como test y los otros <strong>K-1</strong> como train.
      </p>

      <div class="grid-2">
        <div class="card">
          <h3>Lo t√≠pico</h3>
          <ul>
            <li><strong>K = 5</strong> o <strong>K = 10</strong> (muy com√∫n en pr√°ctica).</li>
            <li>En clasificaci√≥n, usa <strong>StratifiedKFold</strong> para mantener proporciones de clases.</li>
            <li>Reporta: media y desviaci√≥n del score.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Ventajas / Desventajas</h3>
          <ul>
            <li><strong>+</strong> Estimaci√≥n m√°s estable que un √∫nico split.</li>
            <li><strong>+</strong> Aprovecha mejor los datos (cada muestra es test una vez).</li>
            <li><strong>‚àí</strong> Es m√°s lento: entrenas el modelo <strong>K veces</strong>.</li>
          </ul>
        </div>
      </div>

      <figure class="media">
        <img src="../img/validacionK.JPG" alt="Validaci√≥n Cruzada K iteraciones" loading="lazy" decoding="async">
        <figcaption>Validaci√≥n Cruzada K iteraciones.</figcaption>
      </figure>

      <pre><code># Idea mental (no es c√≥digo ejecutable)
# for fold in folds:
#   train = datos - fold
#   test  = fold
#   entrenar(modelo, train)
#   score = evaluar(modelo, test)
# devolver media(score), std(score)</code></pre>
    </section>

    <!-- 1.1.2 -->
    <section id="cv-random">
      <h2>1.1.2. Validaci√≥n cruzada aleatoria</h2>

      <p>
        Tambi√©n llamada <strong>repeated random sub-sampling</strong>.
        En vez de partir en K bloques fijos, aqu√≠ se repite N veces:
        se hace un split aleatorio train/test, se entrena y se eval√∫a.
      </p>

      <div class="grid-2">
        <div class="card">
          <h3>Cu√°ndo tiene sentido</h3>
          <ul>
            <li>Cuando quieres controlar el <strong>porcentaje exacto</strong> de train/test en cada repetici√≥n.</li>
            <li>Cuando K-Fold no encaja bien (por ejemplo, por restricciones de tiempo o estructura del dataset).</li>
          </ul>
        </div>
        <div class="card">
          <h3>Pegas t√≠picas</h3>
          <ul>
            <li>Algunas muestras pueden <strong>no salir nunca</strong> en test.</li>
            <li>Otras pueden salir <strong>muchas veces</strong>.</li>
            <li>Necesitas fijar <strong>semilla</strong> (reproducibilidad).</li>
          </ul>
        </div>
      </div>

      <div class="note">
        <strong>Consejo:</strong> si es clasificaci√≥n, intenta que el split sea estratificado (misma proporci√≥n de clases).
      </div>

      <figure class="media">
        <img src="../img/validacionAleatoria.JPG" alt="Validaci√≥n Cruzada Aleatoria" loading="lazy" decoding="async">
        <figcaption>Validaci√≥n Cruzada Aleatoria.</figcaption>
      </figure>
    </section>

    <!-- 1.1.3 -->
    <section id="cv-loo">
      <h2>1.1.3. Validaci√≥n cruzada dejando uno fuera (Leave-One-Out)</h2>

      <p>
        En <strong>Leave-One-Out</strong> (LOO) hacemos algo extremo:
        en cada iteraci√≥n dejamos <strong>1 sola muestra</strong> como test y entrenamos con todas las dem√°s.
        Repetimos esto para <strong>cada muestra</strong> del dataset.
      </p>

      <div class="grid-2">
        <div class="card">
          <h3>Ventajas</h3>
          <ul>
            <li>Aprovecha casi todos los datos para entrenar en cada iteraci√≥n.</li>
            <li>Puede ser √∫til cuando tienes <strong>muy pocas muestras</strong>.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Desventajas</h3>
          <ul>
            <li>Coste enorme: entrenas el modelo <strong>N veces</strong> (N = n¬∫ de muestras).</li>
            <li>La estimaci√≥n puede tener <strong>varianza alta</strong> dependiendo del problema.</li>
          </ul>
        </div>
      </div>

      <figure class="media">
        <img src="../img/validacionUnoFuera.JPG" alt="Validaci√≥n Cruzada Dejando Uno Fuera" loading="lazy" decoding="async">
        <figcaption>Validaci√≥n Cruzada Dejando Uno Fuera.</figcaption>
      </figure>

      <p class="note">
        <strong>Regla pr√°ctica:</strong> LOO solo cuando el dataset es peque√±o y el entrenamiento es barato.
      </p>
    </section>

    <!-- 2 -->
    <section id="hpo">
      <h2>2. Optimizaci√≥n de hiperpar√°metros</h2>

      <p>
        Una vez tienes un modelo que ‚Äúfunciona‚Äù, la pregunta t√≠pica es:
        <strong>¬øc√≥mo me quedo con la mejor versi√≥n posible?</strong>
        Ah√≠ entra la b√∫squeda de hiperpar√°metros.
      </p>

      <div class="card">
        <h3>Dos conceptos que no hay que mezclar</h3>
        <ul>
          <li><strong>Par√°metros</strong>: los aprende el modelo entrenando (pesos en redes, coeficientes en regresi√≥n, etc.).</li>
          <li><strong>Hiperpar√°metros</strong>: los eliges t√∫ antes de entrenar (max_depth, C, n¬∫ de vecinos, learning rate, etc.).</li>
        </ul>
      </div>

      <div class="tips-box">
        <p><strong>Idea clave:</strong> optimizar hiperpar√°metros es ‚Äúprobar configuraciones‚Äù y medir cu√°l generaliza mejor.</p>
      </div>
    </section>

    <!-- 2.1 -->
    <section id="hpo-idea">
      <h2>2.1. Qu√© se est√° optimizando</h2>

      <p>
        El objetivo t√≠pico es maximizar una m√©trica (por ejemplo accuracy/F1/AUC) o minimizar un error
        (MAE/MSE) en validaci√≥n. Para hacerlo bien:
      </p>

      <ul>
        <li>Usa <strong>validaci√≥n cruzada</strong> dentro de la b√∫squeda (mejor estimaci√≥n).</li>
        <li>El conjunto <strong>test</strong> se guarda para el final (examen).</li>
      </ul>

      <div class="note">
        <strong>Trampa com√∫n:</strong> ajustar hiperpar√°metros mirando el test es ‚Äúhacer trampas‚Äù sin querer.
        El test deja de ser un examen si lo usas para decidir.
      </div>

      <div class="card">
        <h3>En scikit-learn lo normal</h3>
        <ul>
          <li><code>GridSearchCV</code> ‚Üí recorre una cuadr√≠cula completa.</li>
          <li><code>RandomizedSearchCV</code> ‚Üí prueba combinaciones aleatorias.</li>
        </ul>
      </div>
    </section>

    <!-- 2.2 -->
    <section id="random-search">
      <h2>2.2. B√∫squeda aleatoria (Random Search)</h2>

      <p>
        Random Search prueba <strong>combinaciones aleatorias</strong> dentro de un espacio de b√∫squeda.
        Es especialmente √∫til cuando:
      </p>

      <ul>
        <li>Hay muchos hiperpar√°metros.</li>
        <li>No sabes cu√°les son los importantes.</li>
        <li>Quieres <strong>buena soluci√≥n r√°pida</strong> con presupuesto limitado.</li>
      </ul>

      <div class="grid-2">
        <div class="card">
          <h3>Ventajas</h3>
          <ul>
            <li><strong>Explora m√°s variedad</strong> con menos intentos.</li>
            <li>Suele encontrar buenas configuraciones antes que Grid Search cuando hay muchos par√°metros.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Desventajas</h3>
          <ul>
            <li>No ‚Äúgarantiza‚Äù probar todas las combinaciones.</li>
            <li>Depende del n¬∫ de iteraciones (presupuesto).</li>
          </ul>
        </div>
      </div>

      <div class="img-placeholder" role="img" aria-label="Diagrama Random Search">
        <strong>üß≠ Visual</strong>
        N puntos repartidos de forma aleatoria en un ‚Äúcuadrado‚Äù de dos hiperpar√°metros.
      </div>

      <details>
        <summary><strong>Autoevaluaci√≥n (tipo test)</strong></summary>
        <p>¬øQu√© t√©cnicas se pueden usar para buscar hiperpar√°metros √≥ptimos?</p>
        <ul>
          <li>‚óã Random Search</li>
          <li>‚óã Grid Search</li>
          <li>‚óã Las dos anteriores</li>
        </ul>
      </details>
    </section>

    <!-- 2.3 -->
    <section id="grid-search">
      <h2>2.3. B√∫squeda en cuadr√≠cula (Grid Search)</h2>

      <p>
        Grid Search define una <strong>lista finita de valores</strong> para cada hiperpar√°metro y prueba
        <strong>todas</strong> las combinaciones. Es √∫til cuando el espacio es peque√±o y razonable.
      </p>

      <div class="grid-2">
        <div class="card">
          <h3>Ventajas</h3>
          <ul>
            <li>Exploraci√≥n <strong>exhaustiva</strong> del grid.</li>
            <li>Reproducible y f√°cil de explicar.</li>
          </ul>
        </div>
        <div class="card">
          <h3>Desventajas</h3>
          <ul>
            <li>Puede explotar en coste (combinaciones = producto cartesiano).</li>
            <li>Si un hiperpar√°metro no es importante, ‚Äúgastas‚Äù intentos igual.</li>
          </ul>
        </div>
      </div>

      <div class="img-placeholder" role="img" aria-label="Diagrama Grid Search">
        <strong>üß± Visual</strong>
        Puntos distribuidos en una rejilla (grid) sobre dos hiperpar√°metros.
      </div>

      <div class="note">
        <strong>Regla r√°pida:</strong> si el grid te sale enorme, o reduces el rango o pasas a Random Search.
      </div>
    </section>

    <!-- 2.4 -->
    <section id="hpo-tips">
      <h2>2.4. Consejos pr√°cticos</h2>

      <div class="grid-2">
        <div class="card">
          <h3>1) Empieza peque√±o</h3>
          <ul>
            <li>Primero encuentra un rango ‚Äúdecente‚Äù.</li>
            <li>Luego afina alrededor de lo que funciona.</li>
          </ul>
        </div>
        <div class="card">
          <h3>2) Siempre con Pipeline</h3>
          <ul>
            <li>Si hay escalado/one-hot/PCA‚Ä¶ m√©telo en <strong>Pipeline</strong>.</li>
            <li>Evitas <strong>data leakage</strong> (fugas de informaci√≥n).</li>
          </ul>
        </div>
      </div>

      <div class="card">
        <h3>3) M√©trica correcta seg√∫n el problema</h3>
        <p>
          Si el dataset est√° desbalanceado, optimizar por accuracy puede llevarte a un modelo in√∫til.
          En esos casos suele ser m√°s razonable optimizar por <strong>F1</strong>, <strong>Recall</strong> o <strong>PR-AUC</strong>.
        </p>
      </div>

      <div class="note">
        <strong>Si quieres hacerlo ‚Äúnivel pro‚Äù:</strong> usa <strong>Nested Cross-Validation</strong>
        (una CV interna para elegir hiperpar√°metros y otra externa para estimar el rendimiento).
      </div>
    </section>

    <!-- 3 -->
    <section id="imbalance">
      <h2>3. Desbalanceo y anomal√≠as</h2>

      <p>
        Aqu√≠ entramos en casos ‚Äúreales‚Äù: datos que no est√°n limpios o equilibrados.
        Dos escenarios t√≠picos:
      </p>
      <ul>
        <li><strong>Dataset desbalanceado</strong>: una clase domina a las dem√°s (fraude, enfermedades raras, spam‚Ä¶).</li>
        <li><strong>Anomal√≠as</strong>: casos extra√±os/irregulares sin etiqueta clara (outliers, comportamiento raro, fraude ‚Äúnuevo‚Äù).</li>
      </ul>

      <div class="img-placeholder" role="img" aria-label="Ejemplo de desbalanceo">
        <strong>üìâ Visual</strong>
        Barras ‚Äúmuchas transacciones‚Äù vs ‚Äúpocos fraudes‚Äù (clase minoritaria).
      </div>
    </section>

    <!-- 3.1 -->
    <section id="imbalance-ds">
      <h2>3.1. Dataset desbalanceado</h2>

      <p>
        En un dataset desbalanceado, el modelo puede sacar n√∫meros ‚Äúbonitos‚Äù sin ser √∫til.
        Ejemplo t√≠pico: 99% no fraude / 1% fraude. Un modelo que siempre diga ‚Äúno fraude‚Äù tendr√≠a 99% de accuracy,
        pero <strong>no detecta nada</strong>.
      </p>

      <div class="tips-box">
        <p><strong>Se√±ales de alarma:</strong></p>
        <ul>
          <li>Accuracy alto, pero el modelo falla la clase minoritaria.</li>
          <li>Recall bajo en la clase importante (fraude/enfermedad).</li>
          <li>Resultados muy distintos seg√∫n el split.</li>
        </ul>
      </div>

      <div class="card">
        <h3>Qu√© hacer antes de tocar el dataset</h3>
        <ul>
          <li>Usar <strong>m√©tricas adecuadas</strong>: Precision/Recall/F1, PR-AUC, Balanced Accuracy.</li>
          <li>Usar <strong>Stratified</strong> split / StratifiedKFold.</li>
          <li>Mirar errores por clase (no solo un n√∫mero global).</li>
        </ul>
      </div>

      <details>
        <summary><strong>Autoevaluaci√≥n (V/F)</strong></summary>
        <p>
          Cuando el dataset est√° desbalanceado, suele ocurrir que obtenemos un alto valor de precisi√≥n en la clase minoritaria
          y un bajo recall en la clase mayoritaria.
        </p>
        <ul>
          <li>‚óã Verdadero</li>
          <li>‚óã Falso</li>
        </ul>
        <p class="note">
          Pista: lo t√≠pico es lo contrario: el modelo se ‚Äúacomoda‚Äù en la mayoritaria y suele sufrir en el <strong>recall de la minoritaria</strong>.
        </p>
      </details>
    </section>

    <!-- 3.1.1 -->
    <section id="undersampling">
      <h2>3.1.1. Submuestreo (Under-sampling)</h2>

      <p>
        El submuestreo consiste en <strong>reducir</strong> el n√∫mero de ejemplos de la clase mayoritaria
        para equilibrar el dataset.
      </p>

      <div class="grid-2">
        <div class="card">
          <h3>Ventaja</h3>
          <p>R√°pido y sencillo. Reduce tama√±o del dataset ‚Üí entrenar es m√°s barato.</p>
        </div>
        <div class="card">
          <h3>Desventaja</h3>
          <p>Puedes perder informaci√≥n importante: tiras casos reales de la clase mayoritaria.</p>
        </div>
      </div>

      <div class="img-placeholder" role="img" aria-label="Diagrama under-sampling">
        <strong>üß± Diagrama</strong>
        Bloque grande (mayoritaria) que se reduce hasta igualar el bloque peque√±o (minoritaria).
      </div>

      <p class="note">
        √ötil cuando la clase mayoritaria es enorme y ‚Äúsobran‚Äù ejemplos redundantes.
      </p>
    </section>

    <!-- 3.1.2 -->
    <section id="oversampling">
      <h2>3.1.2. Sobremuestreo (Over-sampling + SMOTE)</h2>

      <p>
        El sobremuestreo consiste en <strong>a√±adir</strong> ejemplos a la clase minoritaria para equilibrar.
        Hay dos enfoques:
      </p>
      <ul>
        <li><strong>Repetir</strong> ejemplos existentes (simple, pero puede sobreajustar).</li>
        <li>Generar ejemplos sint√©ticos (por ejemplo <strong>SMOTE</strong>).</li>
      </ul>

      <div class="grid-2">
        <div class="card">
          <h3>Ventaja</h3>
          <p>No pierdes informaci√≥n de la mayoritaria.</p>
        </div>
        <div class="card">
          <h3>Desventaja</h3>
          <p>Aumenta el dataset; si generas mal, puedes introducir ruido o sobreajuste.</p>
        </div>
      </div>

      <div class="img-placeholder" role="img" aria-label="Diagrama over-sampling">
        <strong>üìà Diagrama</strong>
        Bloque peque√±o (minoritaria) que se ‚Äúrellena‚Äù hasta acercarse al tama√±o de la mayoritaria.
      </div>

      <div class="note">
        <strong>SMOTE</strong> crea puntos ‚Äúinterpolados‚Äù entre ejemplos minoritarios (no solo copias).
        Si lo usas, hazlo dentro de un Pipeline para evitar fuga de informaci√≥n.
      </div>
    </section>

    <!-- 3.1.3 -->
    <section id="other-strats">
      <h2>3.1.3. Otras estrategias</h2>

      <div class="card">
        <h3>Opciones que suelen funcionar bien en pr√°ctica</h3>
        <ul>
          <li><strong>class_weight</strong> / pesos de clase (penaliza m√°s errores en la minoritaria).</li>
          <li><strong>Threshold moving</strong>: cambiar el umbral de decisi√≥n (por ejemplo 0.3 en vez de 0.5).</li>
          <li><strong>Ensembles</strong>: Random Forest, Gradient Boosting, XGBoost (a veces con pesos).</li>
          <li><strong>Recoger m√°s datos</strong> de la minoritaria (si es posible).</li>
        </ul>
      </div>

      <div class="tips-box">
        <p><strong>Checklist r√°pido en desbalanceo</strong></p>
        <ul>
          <li>¬øMi split es estratificado?</li>
          <li>¬øEstoy optimizando una m√©trica adecuada (F1/Recall/PR-AUC)?</li>
          <li>¬øHe probado class_weight antes de ‚Äútoquetear‚Äù el dataset?</li>
          <li>¬øMi pipeline evita data leakage?</li>
        </ul>
      </div>
    </section>

    <!-- 3.2 -->
    <section id="anomalies">
      <h2>3.2. Detecci√≥n de anomal√≠as</h2>

      <p>
        Una <strong>anomal√≠a</strong> es un caso raro o irregular. A veces no tenemos etiqueta ‚Äúan√≥malo / normal‚Äù,
        as√≠ que usamos t√©cnicas no supervisadas o semi-supervisadas.
      </p>

      <div class="card">
        <h3>Casos t√≠picos</h3>
        <ul>
          <li>Fraude ‚Äúnuevo‚Äù que no aparece en el hist√≥rico.</li>
          <li>Lecturas de sensores fuera de rango (fallos).</li>
          <li>Usuarios con comportamiento extra√±o (bots, ataques).</li>
        </ul>
      </div>

      <div class="note">
        <strong>Ojo:</strong> ‚Äúanomal√≠a‚Äù no siempre significa error: puede ser un caso v√°lido pero raro.
      </div>
    </section>

    <!-- 3.2.1 -->
    <section id="pca-ae">
      <h2>3.2.1. Reducci√≥n dimensional: PCA y autoencoders</h2>

      <p>
        Una estrategia com√∫n es proyectar los datos a un espacio donde sea f√°cil separar ‚Äúlo normal‚Äù de ‚Äúlo raro‚Äù.
      </p>

      <h3>PCA (Principal Component Analysis)</h3>
      <ul>
        <li>Reduce dimensiones buscando direcciones con mayor varianza.</li>
        <li>√ötil para visualizar (2D/3D) y detectar puntos alejados.</li>
        <li>Funciona bien como <strong>paso previo</strong> antes de otro detector.</li>
      </ul>

      <h3>Autoencoders</h3>
      <ul>
        <li>Una red neuronal que aprende a reconstruir la entrada.</li>
        <li>Se entrena con datos ‚Äúnormales‚Äù y las anomal√≠as suelen tener <strong>alto error de reconstrucci√≥n</strong>.</li>
        <li>Potente cuando las relaciones son no lineales y hay muchos features.</li>
      </ul>

      <div class="img-placeholder" role="img" aria-label="Esquema Autoencoder">
        <strong>üß† Esquema</strong>
        Entrada ‚Üí encoder ‚Üí espacio latente peque√±o ‚Üí decoder ‚Üí reconstrucci√≥n.
      </div>

      <p class="note">
        Si vas a usar autoencoders para anomal√≠as, intenta entrenarlos con datos lo m√°s ‚Äúlimpios‚Äù posible (normales).
      </p>
    </section>

    <!-- 3.2.2 -->
    <section id="iforest">
      <h2>3.2.2. Isolation Forest</h2>

      <p>
        <strong>Isolation Forest</strong> detecta anomal√≠as aislando puntos mediante particiones aleatorias.
        Intuici√≥n: las anomal√≠as suelen necesitar <strong>menos cortes</strong> para quedar ‚Äúsolas‚Äù.
      </p>

      <div class="grid-2">
        <div class="card">
          <h3>Pros</h3>
          <ul>
            <li>R√°pido y escalable.</li>
            <li>Funciona bien con muchos features.</li>
            <li>No necesita etiquetas (normal/an√≥malo).</li>
          </ul>
        </div>
        <div class="card">
          <h3>Contras</h3>
          <ul>
            <li>Necesitas estimar <code>contamination</code> (proporci√≥n esperada de anomal√≠as).</li>
            <li>Requiere buen preprocesado (escala/categ√≥ricas) si el dataset lo necesita.</li>
          </ul>
        </div>
      </div>

      <pre><code># Mini-ejemplo conceptual (scikit-learn)
# from sklearn.ensemble import IsolationForest
# iso = IsolationForest(contamination=0.02, random_state=42)
# y_pred = iso.fit_predict(X)  # -1 anomal√≠a, 1 normal</code></pre>
    </section>

    <!-- 3.2.3 -->
    <section id="anomaly-tips">
      <h2>3.2.3. Consejos de evaluaci√≥n</h2>

      <div class="card">
        <h3>C√≥mo no enga√±arte</h3>
        <ul>
          <li>Si tienes etiquetas, usa un conjunto de validaci√≥n y mide <strong>Precision/Recall</strong> de anomal√≠as.</li>
          <li>Si NO tienes etiquetas, valida con revisi√≥n manual o con ‚Äúcasos conocidos‚Äù.</li>
          <li>Cuida el preprocesado: escalado, one-hot, imputaci√≥n‚Ä¶ (y siempre dentro de Pipeline).</li>
        </ul>
      </div>

      <div class="note">
        En detecci√≥n de anomal√≠as, el objetivo suele ser <strong>priorizar</strong> casos para revisar, no ‚Äúacertar 100%‚Äù.
        Lo que importa es reducir falsos negativos en lo cr√≠tico y que la lista de alertas sea manejable.
      </div>
    </section>

    <footer>
      <p>¬© 2025 ‚Äî Material docente DigiTech. Jose Miguel Mart√≠nez.</p>
    </footer>
  </div>

  <a class="top" href="#top" aria-label="Volver arriba">‚Üë</a>
</body>
</html>

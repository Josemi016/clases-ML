<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Árboles de decisión — Parte 2</title>
  <!-- MISMO CSS QUE LA PARTE 1 -->
  <style>
    :root {
      --fg: #111827; /* slate-900 */
      --muted: #4b5563; /* gray-600 */
      --bg: #ffffff;
      --brand: #0ea5e9; /* sky-500 */
      --brand-ink: #075985; /* sky-800 */
      --card: #f8fafc; /* slate-50 */
      --code: #111827; /* slate-900 */
      --border: #e5e7eb; /* gray-200 */
      /* accent */
      --h1: #1d4ed8; /* blue-700 */
      --h2: #6d28d9; /* violet-700 */
      --h3: #0284c7; /* sky-600 */
      --section-underline: #dbeafe; /* blue-100 */
      --divider: #e5e7eb; /* gray-200 */
    }
    html, body { background: var(--bg); color: var(--fg); font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; }
    .page { max-width: 920px; margin: auto; padding: 2rem 1.25rem 6rem; line-height: 1.65; }
    header h1 { font-size: clamp(1.6rem, 2.5vw + 1rem, 2.4rem); margin: 0 0 .25rem; color: var(--h1); letter-spacing: -0.01em; }
    header p.lead { color: var(--muted); margin: 0 0 1.25rem; }
    .breadcrumbs { font-size: .9rem; color: var(--muted); margin-bottom: .5rem; }
    .breadcrumbs a { color: var(--muted); text-decoration: none; }
    nav.toc { background: var(--card); border: 1px solid var(--border); border-radius: .75rem; padding: 1rem; margin: 1.25rem 0 2rem; }
    nav.toc strong { display: block; margin-bottom: .5rem; }
    nav.toc a { display: block; color: var(--brand-ink); text-decoration: none; padding: .25rem 0; }
    h2 { margin-top: 2.25rem; font-size: 1.6rem; color: var(--h2); padding-bottom: .35rem; border-bottom: 1px solid var(--section-underline); }
    h3 { margin-top: 1.5rem; font-size: 1.25rem; color: var(--h3); }
    .page section + section { border-top: 1px solid var(--divider); margin-top: 2.25rem; padding-top: 2rem; }
    .note { background: #ecfeff; border-left: 4px solid var(--brand); padding: .75rem 1rem; border-radius: .5rem; }
    .card { background: var(--card); border: 1px solid var(--border); border-radius: .75rem; padding: 1rem; }
    code, pre { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font-size: .95em; }
    pre { background: #0b1020; color: #e2e8f0; border-radius: .5rem; padding: 1rem; overflow: auto; }
    .pill { display: inline-block; border: 1px solid var(--border); border-radius: 999px; padding: .1rem .6rem; font-size: .875rem; color: var(--muted); background: #fff; }
    details { border: 1px solid var(--border); border-radius: .5rem; padding: .75rem 1rem; background: #fff; }
    details + details { margin-top: .75rem; }
    footer { margin-top: 3rem; font-size: .9rem; color: var(--muted); }
    .top { position: fixed; right: 1rem; bottom: 1rem; background: var(--brand); color: #fff; border-radius: 999px; padding: .6rem .8rem; text-decoration: none; box-shadow: 0 6px 18px rgba(2,132,199,.3); }
    figure.media { margin: 1rem 0 1.25rem; }
    figure.media img { max-width: 100%; height: auto; display: block; border-radius: .5rem; }
    figure.media figcaption { margin-top: .5rem; text-align: center; color: var(--muted); font-size: .95rem; }
  </style>
</head>
<body>
  <div class="page">
    <header id="top">
      <div class="breadcrumbs">Sistemas de Aprendizaje Automático → Tema 2 → <span class="pill">Parte 2</span></div>
      <h1>Árboles de decisión</h1>
      <p class="lead">Guía docente con definiciones, ejemplos y espacios para tus propias figuras.</p>
    </header>

    <nav class="toc" aria-label="Tabla de contenidos">
      <strong>Índice de la página</strong>
      <a href="#definicion">1. ¿Qué son y para qué se utilizan?</a>
      <a href="#representacion">2. Representación (nodos, hojas, ramas)</a>
      <a href="#ventajas">2. Ventajas y desventajas</a>
      <a href="#tipos-y-criterios">4. ID3, C4.5, CART y criterios de selección</a>
      <a href="#matriz-confusion">5. Matriz de confusión</a>
      <a href="#cross-validation">6. Validación cruzada (k-fold)</a>

    </nav>

    <!-- 1 -->
    <section id="definicion">
      <h2>1. Definición ¿Qué son y para qué se utilizan?</h2>
      <p>Un <strong>árbol de decisión</strong> es un modelo supervisado que aprende <em>reglas en forma de preguntas</em> sobre las características para clasificar ejemplos o predecir valores.</p>
      <ul>
        <li><strong>Clasificación:</strong> aprobar/denegar un crédito, detectar spam, diagnosticar una enfermedad.</li>
        <li><strong>Regresión:</strong> estimar precio de vivienda, consumo energético o demanda diaria.</li>
      </ul>
      <figure class="media">
        <img src="../img/parte2-arbol-decision.JPG" alt="Tabla de ejemplo - Problema Jugar al Tenis" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Problema Árbol de Decisión.</figcaption>
    </section>
    <section id="representacion">
      <h2>2. Representación (nodos, hojas, ramas)</h2>
      <ul>
        <li><strong>Nodo interno:</strong> pregunta/regla (p. ej., <code>edad &lt; 30</code>).</li>
        <li><strong>Ramas:</strong> resultados de la regla (sí/no o múltiples valores).</li>
        <li><strong>Hoja:</strong> decisión final (clase) o valor numérico (regresión).</li>
      </ul>
      <div class="note">Consejo: limita <em>profundidad</em>, tamaño mínimo de hojas o usa <em>poda</em> para controlar complejidad.</div>
      <figure class="media">
        <img src="../img/parte2-arbol-decision - Ejemplo .JPG" alt="Esquema conceptual de árbol de decisión" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Diagrama sencillo de un árbol con etiquetas</figcaption>
      </figure>
      <p class="note">
        Recurso:
        <a href="https://fhernanb.github.io/libro_mod_pred/arb-de-regre.html#%C3%A1rbol-de-regresi%C3%B3n"
         target="_blank" rel="noopener noreferrer">
          Arbol de Regresión
        </a>
      </p>
    </section>

    <!-- 2 -->
    <section id="ventajas" class="card">
      <h2>3. Ventajas y desventajas</h2>
      <ul>
        <li><strong>Ventajas:</strong> interpretables, no requieren demasiada preparación de datos, manejan variables numéricas y categóricas, capturan interacciones y no linealidades.</li>
        <li><strong>Desventajas:</strong> sensibles a pequeñas variaciones en datos, riesgo de <em>sobreajuste</em> si son muy profundos, cortes ortogonales (ejes) que a veces no capturan fronteras complejas.</li>
      </ul>
      <figure class="media">
        <img src="../img/Modul-7_3.-Perbedaan-Over-dan-Under.png" alt="Sobreajuste" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Sobreajuste.</figcaption>
      </figure>
      <figure class="media">
        <img src="../img/underfit-goodfit-overfit-1.png" alt="Sobreajuste" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Sobreajuste.</figcaption>
      </figure>
      <figure class="media">
        <img src="../img/estrategias-evitar overfitting.JPG" alt="Soluciones al sobreajuste" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Estrategias mitigar el sobreajuste.</figcaption>
      </figure>
      <!-- justo después del </ul> de Ventajas y desventajas -->
      <p class="note">
        Recurso interactivo:
        <a href="https://mlu-explain.github.io/decision-tree/"
         target="_blank" rel="noopener noreferrer">
          Decision Trees — MLU-Explain
        </a>
      </p>

    </section>

    <!-- 4 -->
    <section id="tipos-y-criterios">
      <h2>4. ID3, C4.5, CART y criterios de selección</h2>

      <h3>4.1. Definiciones rápidas</h3>
      <dl>
        <dt><strong>ID3</strong></dt>
        <dd>Elige el atributo con <em>mayor ganancia de información</em> (basada en entropía). Históricamente para variables categóricas.</dd>
        <d2><strong>Entropía: </strong>mide el grado de desinformación de un sistema</d2>
        <figure class="media">
        <img src="../img/entropía.JPG" alt="Entropía" width="1200" height="640" loading="lazy" decoding="async">
        <figcaption>Figura — Entropía.</figcaption>
      </figure>

        <dt><strong>C4.5</strong></dt>
        <dd>El C4.5 se basa en el ID3, por lo tanto, la estructura principal de ambos métodos es la misma.  El C4.5 construye un árbol de decisión mediante el algoritmo "divide y vencerás" y evalúa la información en cada caso basada en la ganancia de información y proporciona mejores resultados si los atributos tienen muchos posibles valores. Realiza una poda tras la generación del árbol (pospoda) con el fin de mejorar la generalización del modelo: elimina nodos que al podar mejoran la precisión en la clasificación.

        <dt><strong>CART(Classification and Regression Tree)</strong></dt>
        <dd>Árbol binario. Usa <em>impureza de Gini</em> para clasificación y <em>MSE</em> para regresión.
        <d2><strong>Impureza de Gini: </strong>mide la frecuencia con la que se clasifica erróneamente un atributo elegido al azar</d2>
      </dl>
      <h3>¿Qué mide cada cosa?</h3>
  <ul>
    <li><strong>Entropía</strong>: cuánta incertidumbre hay (bolsa muy mezclada).</li>
    <li><strong>Gini</strong>: probabilidad de equivocarte al adivinar la clase al azar.</li>
    <li><strong>Ganancia de información</strong>: mezcla antes – mezcla después del corte.</li>
  </ul>

  <h3>¿Qué usa cada algoritmo?</h3>
  <ul>
    <li><strong>ID3</strong>: Entropía + Ganancia (mejor para categóricas; sin poda).</li>
    <li><strong>C4.5</strong>: Entropía + <em>Gain Ratio</em> (corrige “muchos valores”, soporta continuas y poda).</li>
    <li><strong>CART</strong>: <u>Clasificación</u> → Gini; <u>Regresión</u> → MSE. Árbol binario.</li>
  </ul>

  <h3>Reglas rápidas</h3>
  <ul>
    <li>En <code>sklearn</code>, usa CART con <strong>Gini</strong> (rápido). Si quieres teoría de info, elige <strong>entropía</strong>.</li>
    <li>Si un atributo tiene muchísimos valores, <strong>Gain Ratio (C4.5)</strong> evita sesgos.</li>
    <li>Para regresión, olvida Gini/entropía: usa <strong>MSE</strong>.</li>
  </ul>
    </section>

        <!-- 5 -->
    <section id="matriz-confusion">
      <h2>5. Matriz de confusión (definición)</h2>
      <p>Tabla 2×2 para problemas binarios (extensible a multicategoría) que relaciona las <em>predicciones</em> del modelo con las <em>etiquetas reales</em>:</p>
      <figure class="media">
        <img src="../img/matriz-confusion.JPG" alt="Matriz de confusion" width="1100" height="520" loading="lazy" decoding="async">
        <figcaption>Figura — Matriz de confusion.</figcaption>
        </figure>
        <p class="note">
        Recurso interactivo:
        <a href="https://telefonicatech.com/blog/como-interpretar-la-matriz-de-confusion-ejemplo-practico"
         target="_blank" rel="noopener noreferrer">
        Cómo interpretar la matriz de confusión
        </a>
      </p>
        
      <ul>
        <li><strong>TP</strong> (verdadero positivo): positivo bien clasificado.</li>
        <li><strong>FP</strong> (falso positivo): negativo clasificado como positivo.</li>
        <li><strong>FN</strong> (falso negativo): positivo clasificado como negativo.</li>
        <li><strong>TN</strong> (verdadero negativo): negativo bien clasificado.</li>
      </ul>
      <div class="note">A partir de la matriz se calculan métricas como <em>exactitud</em>, <em>precisión</em>, <em>recobrado (recall)</em> y <em>F1</em>.</div>

      <figure class="media">
        <img src="../img/matriz-confusion-formulas.JPG" alt="Matriz de confusión con TP, FP, FN, TN" width="1100" height="560" loading="lazy" decoding="async">
        <figcaption>Figura — Formulas Matriz Confusión.</figcaption>
      </figure>
      <figure class="media">
        <img src="../img/matriz-confusion-formulas2.JPG" alt="Interpretación Fórmulas" width="1100" height="560" loading="lazy" decoding="async">
        <figcaption>Figura — Interpretación Fórmulas.</figcaption>
      </figure>
    </section>
    
    <!-- 6 -->
    <section id="cross-validation" class="card">
      <h2>6. Validación cruzada (k-fold)</h2>
      <p>La <strong>validación cruzada k-fold</strong> reparte los datos en <em>k</em> pliegues; se entrena con k−1 y se valida con el restante, repitiendo k veces y promediando métricas.</p>
      <ul>
        <li><strong>Cuándo usarla:</strong> para estimar rendimiento más estable y elegir hiperparámetros (profundidad, min_samples_split, etc.).</li>
        <li><strong>Valores típicos:</strong> k = 5 o 10.</li>
      </ul>
      <figure class="media">
        <img src="../img/kfold.png" alt="Esquema de validación cruzada k-fold" width="1100" height="520" loading="lazy" decoding="async">
        <figcaption>Figura — Añade aquí tu gráfico de k pliegues.</figcaption>
      </figure>
    </section>


    <footer>
      <p>© 2025 — Material docente DigiTech. Jose Miguel Martínez.</p>
    </footer>
  </div>
  <a class="top" href="#top" aria-label="Volver arriba">↑</a>
</body>
</html>

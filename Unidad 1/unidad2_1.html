<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Árboles de decisión — Parte 2</title>
  <!-- MISMO CSS QUE LA PARTE 1 -->
  <style>
    :root {
      --fg: #111827; /* slate-900 */
      --muted: #4b5563; /* gray-600 */
      --bg: #ffffff;
      --brand: #0ea5e9; /* sky-500 */
      --brand-ink: #075985; /* sky-800 */
      --card: #f8fafc; /* slate-50 */
      --code: #111827; /* slate-900 */
      --border: #e5e7eb; /* gray-200 */
      /* accent */
      --h1: #1d4ed8; /* blue-700 */
      --h2: #6d28d9; /* violet-700 */
      --h3: #0284c7; /* sky-600 */
      --section-underline: #dbeafe; /* blue-100 */
      --divider: #e5e7eb; /* gray-200 */
    }
    html, body { background: var(--bg); color: var(--fg); font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; }
    .page { max-width: 920px; margin: auto; padding: 2rem 1.25rem 6rem; line-height: 1.65; }
    header h1 { font-size: clamp(1.6rem, 2.5vw + 1rem, 2.4rem); margin: 0 0 .25rem; color: var(--h1); letter-spacing: -0.01em; }
    header p.lead { color: var(--muted); margin: 0 0 1.25rem; }
    .breadcrumbs { font-size: .9rem; color: var(--muted); margin-bottom: .5rem; }
    .breadcrumbs a { color: var(--muted); text-decoration: none; }
    nav.toc { background: var(--card); border: 1px solid var(--border); border-radius: .75rem; padding: 1rem; margin: 1.25rem 0 2rem; }
    nav.toc strong { display: block; margin-bottom: .5rem; }
    nav.toc a { display: block; color: var(--brand-ink); text-decoration: none; padding: .25rem 0; }
    h2 { margin-top: 2.25rem; font-size: 1.6rem; color: var(--h2); padding-bottom: .35rem; border-bottom: 1px solid var(--section-underline); }
    h3 { margin-top: 1.5rem; font-size: 1.25rem; color: var(--h3); }
    .page section + section { border-top: 1px solid var(--divider); margin-top: 2.25rem; padding-top: 2rem; }
    .note { background: #ecfeff; border-left: 4px solid var(--brand); padding: .75rem 1rem; border-radius: .5rem; }
    .card { background: var(--card); border: 1px solid var(--border); border-radius: .75rem; padding: 1rem; }
    code, pre { font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; font-size: .95em; }
    pre { background: #0b1020; color: #e2e8f0; border-radius: .5rem; padding: 1rem; overflow: auto; }
    .pill { display: inline-block; border: 1px solid var(--border); border-radius: 999px; padding: .1rem .6rem; font-size: .875rem; color: var(--muted); background: #fff; }
    details { border: 1px solid var(--border); border-radius: .5rem; padding: .75rem 1rem; background: #fff; }
    details + details { margin-top: .75rem; }
    footer { margin-top: 3rem; font-size: .9rem; color: var(--muted); }
    .top { position: fixed; right: 1rem; bottom: 1rem; background: var(--brand); color: #fff; border-radius: 999px; padding: .6rem .8rem; text-decoration: none; box-shadow: 0 6px 18px rgba(2,132,199,.3); }
    figure.media { margin: 1rem 0 1.25rem; }
    figure.media img { max-width: 100%; height: auto; display: block; border-radius: .5rem; }
    figure.media figcaption { margin-top: .5rem; text-align: center; color: var(--muted); font-size: .95rem; }
  </style>
</head>
<body>
  <div class="page">
    <header id="top">
      <div class="breadcrumbs">Sistemas de Aprendizaje Automático → Tema 2 → <span class="pill">Parte 2</span></div>
      <h1>Árboles de decisión</h1>
      <p class="lead">Guía docente con definiciones, ejemplos y espacios para tus propias figuras.</p>
    </header>

    <nav class="toc" aria-label="Tabla de contenidos">
      <strong>Índice de la página</strong>
      <a href="#que-son">1. ¿Qué son y para qué se utilizan?</a>
      <a href="#ventajas">2. Ventajas y desventajas</a>
      <a href="#representacion">3. Representación (nodos, hojas, ramas)</a>
      <a href="#tipos-y-criterios">4. ID3, C4.5, CART y criterios de selección</a>
      <a href="#entropia-validacion">5. Entropía + Entrenamiento y Validación</a>
      <a href="#cross-validation">6. Validación cruzada (k-fold)</a>
      <a href="#matriz-confusion">7. Matriz de confusión</a>
    </nav>

    <!-- 1 -->
    <section id="que-son">
      <h2>1. ¿Qué son y para qué se utilizan?</h2>
      <p>Un <strong>árbol de decisión</strong> es un modelo supervisado que aprende <em>reglas en forma de preguntas</em> sobre las características para clasificar ejemplos o predecir valores.</p>
      <ul>
        <li><strong>Clasificación:</strong> aprobar/denegar un crédito, detectar spam, diagnosticar una enfermedad.</li>
        <li><strong>Regresión:</strong> estimar precio de vivienda, consumo energético o demanda diaria.</li>
      </ul>
      <figure class="media">
        <img src="../img/arbol-que-son.png" alt="Esquema conceptual de árbol de decisión" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Hueco para tu esquema general del modelo.</figcaption>
      </figure>
    </section>

    <!-- 2 -->
    <section id="ventajas" class="card">
      <h2>2. Ventajas y desventajas</h2>
      <ul>
        <li><strong>Ventajas:</strong> interpretables, no requieren demasiada preparación de datos, manejan variables numéricas y categóricas, capturan interacciones y no linealidades.</li>
        <li><strong>Desventajas:</strong> sensibles a pequeñas variaciones en datos, riesgo de <em>sobreajuste</em> si son muy profundos, cortes ortogonales (ejes) que a veces no capturan fronteras complejas.</li>
      </ul>
      <figure class="media">
        <img src="../img/ventajas-desventajas-arbol.png" alt="Ventajas y desventajas del árbol" width="1200" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Coloca aquí una comparativa visual.</figcaption>
      </figure>
    </section>

    <!-- 3 -->
    <section id="representacion">
      <h2>3. Representación (nodos, hojas, ramas)</h2>
      <ul>
        <li><strong>Nodo interno:</strong> pregunta/regla (p. ej., <code>edad &lt; 30</code>).</li>
        <li><strong>Ramas:</strong> resultados de la regla (sí/no o múltiples valores).</li>
        <li><strong>Hoja:</strong> decisión final (clase) o valor numérico (regresión).</li>
      </ul>
      <div class="note">Consejo: limita <em>profundidad</em>, tamaño mínimo de hojas o usa <em>poda</em> para controlar complejidad.</div>
      <figure class="media">
        <img src="../img/representacion-arbol.png" alt="Ejemplo con nodos, ramas y hojas" width="1100" height="600" loading="lazy" decoding="async">
        <figcaption>Figura — Diagrama sencillo de un árbol con etiquetas.</figcaption>
      </figure>
    </section>

    <!-- 4 -->
    <section id="tipos-y-criterios">
      <h2>4. ID3, C4.5, CART y criterios de selección</h2>

      <h3>4.1. Definiciones rápidas</h3>
      <dl>
        <dt><strong>ID3</strong></dt>
        <dd>Elige el atributo con <em>mayor ganancia de información</em> (basada en entropía). Históricamente para variables categóricas.</dd>

        <dt><strong>C4.5</strong></dt>
        <dd>Extiende ID3: maneja continuas con umbrales, valores perdidos y usa <em>proporción de ganancia</em> para evitar sesgos hacia atributos con muchos valores. Incluye <em>poda</em>.</dd>

        <dt><strong>CART</strong></dt>
        <dd>Árbol binario. Usa <em>impureza de Gini</em> para clasificación y <em>MSE</em> para regresión; aplica <em>poda por complejidad</em>.</dd>
      </dl>

      <h3>4.2. Métodos de selección de atributos (con ejemplo numérico)</h3>
      <p>Supongamos un conjunto de 20 ejemplos con objetivo binario: 12 <code>sí</code> y 8 <code>no</code>.</p>

      <h4>a) Ganancia de información (ID3)</h4>
      <pre><code>Entropía del conjunto S:
p_sí = 12/20 = 0.6
p_no = 8/20 = 0.4
H(S) = −(0.6·log₂0.6 + 0.4·log₂0.4) ≈ 0.971 bits

Atributo Color:
- Rojo: 8 elementos (6 sí, 2 no) → H(Rojo) ≈ 0.811
- Azul: 12 elementos (6 sí, 6 no) → H(Azul) = 1.0
H(S|Color) = (8/20)·0.811 + (12/20)·1.0 ≈ 0.925

Ganancia de información:
IG(Color) = H(S) − H(S|Color) ≈ 0.971 − 0.925 = 0.046 bits
      </code></pre>

      <h4>b) Proporción de ganancia (C4.5)</h4>
      <pre><code>SplitInfo(Color) = −[(8/20)·log₂(8/20) + (12/20)·log₂(12/20)] ≈ 0.971
Gain Ratio = IG / SplitInfo ≈ 0.046 / 0.971 ≈ 0.048
      </code></pre>

      <h4>c) Índice Gini (CART)</h4>
      <pre><code>Gini(S) = 1 − (0.6² + 0.4²) = 0.48
Gini(Rojo) = 1 − (0.75² + 0.25²) = 0.375
Gini(Azul) = 1 − (0.5² + 0.5²) = 0.5
Gini tras el split = (8/20)·0.375 + (12/20)·0.5 = 0.45
Mejora Gini = 0.48 − 0.45 = 0.03
      </code></pre>

      <figure class="media">
        <img src="../img/criterios-seleccion.png" alt="Ilustración de entropía, ganancia y Gini" width="1200" height="640" loading="lazy" decoding="async">
        <figcaption>Figura — Deja aquí una lámina con fórmulas y comparativa visual.</figcaption>
      </figure>
    </section>

    <!-- 5 -->
    <section id="entropia-validacion">
      <h2>5. Entropía + Entrenamiento y Validación</h2>

      <h3>5.1. Entropía (definición y ejemplo)</h3>
      <p>La <strong>entropía</strong> mide la impureza/mezcla de clases:</p>
      <pre><code>H(S) = − Σ pᵢ · log₂ pᵢ
Ejemplo: 9 “sí” y 5 “no” → p_sí = 9/14, p_no = 5/14
H(S) ≈ −(0.6429·log₂0.6429 + 0.3571·log₂0.3571) ≈ 0.94 bits
      </code></pre>

      <h3>5.2. Entrenamiento y validación (flujo básico)</h3>
      <ol>
        <li>Divide en <strong>train/test</strong> (por ejemplo, 80/20).</li>
        <li><strong>Entrena</strong> el árbol en train (ajusta profundidad, min_samples_leaf, etc.).</li>
        <li><strong>Valida</strong> con test: exactitud, F1, MAE (si es regresión), etc.</li>
      </ol>
      <div class="note">Ejemplo práctico: construye un árbol para predecir si un cliente compra (sí/no) y evalúalo con exactitud y F1 sobre el conjunto de test.</div>

      <figure class="media">
        <img src="../img/entrenamiento-validacion.png" alt="Diagrama entrenamiento vs validación" width="1200" height="620" loading="lazy" decoding="async">
        <figcaption>Figura — Espacio para tu diagrama de flujo de entrenamiento/validación.</figcaption>
      </figure>
    </section>

    <!-- 6 -->
    <section id="cross-validation" class="card">
      <h2>6. Validación cruzada (k-fold)</h2>
      <p>La <strong>validación cruzada k-fold</strong> reparte los datos en <em>k</em> pliegues; se entrena con k−1 y se valida con el restante, repitiendo k veces y promediando métricas.</p>
      <ul>
        <li><strong>Cuándo usarla:</strong> para estimar rendimiento más estable y elegir hiperparámetros (profundidad, min_samples_split, etc.).</li>
        <li><strong>Valores típicos:</strong> k = 5 o 10.</li>
      </ul>
      <figure class="media">
        <img src="../img/kfold.png" alt="Esquema de validación cruzada k-fold" width="1100" height="520" loading="lazy" decoding="async">
        <figcaption>Figura — Añade aquí tu gráfico de k pliegues.</figcaption>
      </figure>
    </section>

    <!-- 7 -->
    <section id="matriz-confusion">
      <h2>7. Matriz de confusión (definición)</h2>
      <p>Tabla 2×2 para problemas binarios (extensible a multicategoría) que relaciona las <em>predicciones</em> del modelo con las <em>etiquetas reales</em>:</p>
      <pre><code>                 Clase real
               Pos      Neg
Pred Pos   →   TP       FP
Pred Neg   →   FN       TN
      </code></pre>
      <ul>
        <li><strong>TP</strong> (verdadero positivo): positivo bien clasificado.</li>
        <li><strong>FP</strong> (falso positivo): negativo clasificado como positivo.</li>
        <li><strong>FN</strong> (falso negativo): positivo clasificado como negativo.</li>
        <li><strong>TN</strong> (verdadero negativo): negativo bien clasificado.</li>
      </ul>
      <div class="note">A partir de la matriz se calculan métricas como <em>exactitud</em>, <em>precisión</em>, <em>recobrado (recall)</em> y <em>F1</em>.</div>

      <figure class="media">
        <img src="../img/matriz-confusion.png" alt="Matriz de confusión con TP, FP, FN, TN" width="1100" height="560" loading="lazy" decoding="async">
        <figcaption>Figura — Deja aquí tu imagen de matriz de confusión.</figcaption>
      </figure>
    </section>

    <footer>
      <p>© 2025 — Material docente DigiTech. Jose Miguel Martínez.</p>
    </footer>
  </div>
  <a class="top" href="#top" aria-label="Volver arriba">↑</a>
</body>
</html>
